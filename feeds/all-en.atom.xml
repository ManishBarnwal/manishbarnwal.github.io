<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Manish Barnwal</title><link href="http://manishbarnwal.github.io/" rel="alternate"></link><link href="http://manishbarnwal.github.io/feeds/all-en.atom.xml" rel="self"></link><id>http://manishbarnwal.github.io/</id><updated>2016-06-27T07:00:00-03:00</updated><entry><title>My first attempt at public speaking</title><link href="http://manishbarnwal.github.io/blog/2016/06/27/first_attempt_at_public%20speaking/" rel="alternate"></link><updated>2016-06-27T07:00:00-03:00</updated><author><name>Manish Barnwal</name></author><id>tag:manishbarnwal.github.io,2016-06-27:blog/2016/06/27/first_attempt_at_public speaking/</id><summary type="html">&lt;p&gt;Having graduated from college, it was just 6 months into my new job that I was asked to give a tech-talk on &lt;em&gt;Introduction to Data Science&lt;/em&gt;. Imagine the thrill and fright of a fresher when he is presented with a situation like this. The first thing I asked my manager was — how many people are we expecting in the audience? Notice the fright in the question. I was scared that I might screw up in front of a large audience. I may not be able to present the talk eloquently, the audience may laugh at me and all those crappy thoughts that quickly clouds your mind with fear and uncertainty.&lt;/p&gt;
&lt;h1&gt;&lt;/h1&gt;
&lt;p&gt;Without much thought and ignoring the above questions, I straight away agreed to present the talk. &lt;strong&gt;The plan was simple&lt;/strong&gt;. Commit to the task and then learn how to do it. In a few days, after a lot many iterations I had the presentation ready with me. I had not prepared any script or dialogues for the talk. The reason being, I wanted to give an impromptu talk. Days passed and I got busy in routine office work and meeting project deadlines.&lt;/p&gt;
&lt;h1&gt;&lt;/h1&gt;
&lt;p&gt;Writing and public-speaking was something that has always fascinated me. I had read many a posts on effective public-speaking. Now was the time to apply whatever I had read about it.&lt;/p&gt;
&lt;h1&gt;&lt;/h1&gt;
&lt;p&gt;The day had come when I had to give the tech-talk. That morning, I woke up a little early and I looked at a few videos on dealing with the stage-fear. I found this video in particular to be helpful.&lt;/p&gt;
&lt;h1&gt;&lt;/h1&gt;
&lt;p&gt;It’s not that I had not practiced at all. We had a few dry runs. Frankly, I didn’t had the exact lines that I intended to say. I had just planned the overall flow of the talk. As I had read on various blogs on public-speaking, I reached the conference room a little early, walked down the room confidently, talked to some of my colleagues about random topics so as to divert the attention and calm the nerves. &lt;/p&gt;
&lt;h1&gt;&lt;/h1&gt;
&lt;p&gt;Within a few minutes, the room got packed with folks from various teams. I hadn’t expected these many people to turn around. Nevertheless, I was happy and confident. I kept saying this to myself — &lt;em&gt;you are going to rock today! So many people have come just to listen to you. You know this stuff. This is your bread and butter&lt;/em&gt;. I took a few deep breaths and started the talk. &lt;/p&gt;
&lt;h1&gt;&lt;/h1&gt;
&lt;p&gt;After first few minutes of the talk, I started reading some of the faces in the audience, trying to understand if they are following what was being spoken. A good proxy for this include people asking questions, nodding to your statements in agreement, and making notes. I could see the audience doing these. So the feedback was good and I continued with the talk.&lt;/p&gt;
&lt;h1&gt;&lt;/h1&gt;
&lt;p&gt;It was not all that easy. I stammered in between, fell short of the right words, the throat felt thirsty, some of the faces in audience looked scary but somehow the confidence in me was at peak. &lt;strong&gt;I was happy talking about something that I enjoyed doing&lt;/strong&gt;.&lt;/p&gt;
&lt;h1&gt;&lt;/h1&gt;
&lt;p&gt;It has been almost a year since I had presented this talk. Now when I think about it, I feel good. I feel accomplished. I know I could have screwed up badly. I had to start somewhere. And today I am happy that I did take that chance.&lt;/p&gt;
&lt;h1&gt;&lt;/h1&gt;
&lt;p&gt;Next time, don’t let that chance pass away. Take that risk, prepare well and make it your first attempt at public speaking. We all need to start somewhere.&lt;/p&gt;</summary><category term="life"></category><category term="thoughts"></category><category term="nostalgia"></category></entry><entry><title>Understanding HIVE for data science people</title><link href="http://manishbarnwal.github.io/blog/2016/06/22/understanding_hive_data_science/" rel="alternate"></link><updated>2016-06-22T04:43:00-03:00</updated><author><name>Manish Barnwal</name></author><id>tag:manishbarnwal.github.io,2016-06-22:blog/2016/06/22/understanding_hive_data_science/</id><summary type="html">&lt;p&gt;I have been working as Statistical analyst for the last 1.5 years and fortunately I got to work on Hadoop on one of my initial projects. Hadoop sounds scary to a lot of people and I am no exception. In this post, I would make an attempt to explain HIVE-the data warehouse for Hadoop ecosystem. &lt;/p&gt;
&lt;p&gt;What is HIVE? And why as an analyst I should care about it?&lt;/p&gt;
&lt;p&gt;HIVE is the part of the Hadoop infrastructure where data gets stored and you can write your query to fetch data from HIVE (tables). Now when I had started working on Hadoop, I knew a little SQL and a tad little of data science. I had take a few courses on Statistics during my college but then who really studies in college! Having allocated to a project which required an understanding of Hadoop, I planned how I need to understand this system so that I can contribute my best to the project.&lt;/p&gt;</summary><category term="Hive"></category><category term="hadoop"></category><category term="big data"></category></entry><entry><title>Deploying ML Apps using Python and Flask- Learning about Flask - Part 1</title><link href="http://manishbarnwal.github.io/blog/2016/01/10/deploying_ML_Apps_using_Python_and_Flask/" rel="alternate"></link><updated>2016-01-10T04:43:00-02:00</updated><author><name>Manish Barnwal</name></author><id>tag:manishbarnwal.github.io,2016-01-10:blog/2016/01/10/deploying_ML_Apps_using_Python_and_Flask/</id><summary type="html">&lt;p&gt;It has been a long time since I wrote anything on my blog. So thought about giving everyone a treat this time. Or so I think it is.&lt;/p&gt;
&lt;p&gt;Recently I was thinking about a way to deploy all these machine learning models I create in python. I searched through the web but couldn't find anything nice and easy. 
Then I fell upon &lt;a href="http://sebastianraschka.com/blog/2015/writing-pymle.html"&gt;this book&lt;/a&gt; by Sebastian Rashcka and I knew that it was what I was looking for. 
To tell you the truth I did had some experience in Flask earlier but this book made it a whole lot easier to deploy a machine learning model in flask.&lt;/p&gt;
&lt;p&gt;So today I am going to give a brief intro about Flask Apps and how to deploy them using a service called Openshift. &lt;/p&gt;
&lt;h4&gt;So What is flask?&lt;/h4&gt;
&lt;p&gt;Flask is a Python Web Framework that makes it easier to create webapps from python. &lt;/p&gt;
&lt;h4&gt;And Openshift?&lt;/h4&gt;
&lt;p&gt;Openshift is a free service(if we only use 1 small instance) which lets us use their services to deploy our flask web-apps. &lt;/p&gt;
&lt;p&gt;So that we don't get lost, let me tell you the flow of this post. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First of all we will learn about the &lt;strong&gt;installation&lt;/strong&gt;* of Openshift and Flask.&lt;/li&gt;
&lt;li&gt;We will create a &lt;strong&gt;Hello World&lt;/strong&gt; application using Flask.&lt;/li&gt;
&lt;li&gt;We will work on creating a very &lt;strong&gt;simple calculator App&lt;/strong&gt; that operates on two numbers provided by the user. This will help us in understanding how user forms work with Flask by implementing a barebones app.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Installation:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Create your &lt;a href="https://www.openshift.com/app/account/new"&gt;FREE OpenShift account Here&lt;/a&gt; Very simple sign-up email + password only&lt;/li&gt;
&lt;li&gt;Install the &lt;a href="https://www.openshift.com/developers/install-the-client-tools"&gt;OpenShift Client Tools&lt;/a&gt;. Use these directions for your particular Operating System these tools have a command line interface and allow more control over your app. The OpenShift tool requires an installation of Ruby.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now once you do this you have installed Openshift Client tools on your system.&lt;/p&gt;
&lt;h2&gt;Helloworld&lt;/h2&gt;
&lt;p&gt;So now I am going to do a lot of things in this post. But don't get bothered much it is just code and HTML quirks. I will try to provide enough details on which parts are necessary.
First of all, you will need to create a domain on Openshift platform. This can be done by using:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;rhc domain create -n DomainName -l EmailAddress -p password
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
For this example I created:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;rhc domain create -n mlwhiz -l MyEmailAddress -p Mypassword
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
In the free version for Openshift you can run 3 web-apps with a single domain. 
For example I can create a maximum of 3 webapps whose web address would be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;myappname1-mlwhiz.rhcloud.com&lt;/li&gt;
&lt;li&gt;myappname2-mlwhiz.rhcloud.com&lt;/li&gt;
&lt;li&gt;myappname3-mlwhiz.rhcloud.com&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once we create a domain we need to create a webapp:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;rhc app create HelloWorld python-2.7
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
This creates the app named helloworld for us. The app currently resides at this address on web: http://helloworld-mlwhiz.rhcloud.com/
This command also creates a folder where our app resides. cd into this folder.
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cd helloworld
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
Now get a basic template to work upon in this directory. You can think of this as a starter code for flask. We can do this by pulling and merging from Github using the following commands.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;git remote add upstream -m master git://github.com/openshift/flask-example.git
git pull -s recursive -X theirs upstream master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
Use Virtualenv to isolate Python development environments. It’s a tool that allows you setup an isolated, self-contained Python environment in a folder on your dev box. This way you can experiment with various versions of Python without affecting your system wide configurations:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;brew install python-virtualenv
cd helloworld/wsgi/
virtualenv venv --python=python2.7
#Activate the virtual environment
. venv/bin/activate
# Install all these into your virtual python environment.
pip install flask flask-wtf flask-babel markdown flup 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
Now Change the name of flaskapp.py in wsgi to run.py&lt;/p&gt;
&lt;p&gt;put this code in run.py
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;import os
from flask import Flask
app = Flask(&lt;strong&gt;name&lt;/strong&gt;)
@app.route('/')
def home():
    """Render website's home page."""
    return 'Hello World!'
if &lt;strong&gt;name&lt;/strong&gt; == '&lt;strong&gt;main&lt;/strong&gt;':
    app.run(debug="True")
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Also change the file named application to:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;#!/usr/bin/python
import os
import sys
sys.path.insert(0, os.path.dirname(&lt;strong&gt;file&lt;/strong&gt;) or '.')
PY_DIR = os.path.join(os.environ['OPENSHIFT_HOMEDIR'], "python")
virtenv = PY_DIR + '/virtenv/'
PY_CACHE = os.path.join(virtenv, 'lib', os.environ['OPENSHIFT_PYTHON_VERSION'], 'site-packages')
os.environ['PYTHON_EGG_CACHE'] = os.path.join(PY_CACHE)
virtualenv = os.path.join(virtenv, 'bin/activate_this.py')
try:
    exec(open(virtualenv).read(), dict(&lt;strong&gt;file&lt;/strong&gt;=virtualenv))
except IOError:
    pass
from run import app as application
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Run this to host your app:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cd helloworld/wsgi
python run.py
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;You should be able to see your app on: http://127.0.0.1:5000/
You can deploy this webapp to Openshift using:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cd helloworld
git add .
git commit -a -m "Initial deployment of this app to the web"
git push
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Open http://helloworld-mlwhiz.rhcloud.com/ in your browser. You would see Hello World! there. Now we have got a very basic structure complete. &lt;/p&gt;
&lt;h2&gt;Our Simple Calculator App:&lt;/h2&gt;
&lt;p&gt;We will now work on creating a app that operates on two numbers provided by the user. The functions possible are +,- and *.
You can see this web app in action &lt;a href="http://helloworld-mlwhiz.rhcloud.com/"&gt;here&lt;/a&gt; before moving on. 
This app will help us in understanding how user forms work with Flask and how to manage user inputs in Flask. 
First of all change the code in run.py to&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;import os
from flask import Flask,render_template, request
from wtforms import Form, TextAreaField, validators,SelectField

app = Flask(__name__)

# Code to create a WTForm with three fields. 2 text fields and 1 dropdown menu.
class OutputForm(Form):
    myChoices=[('+', '+'), ('-', '-'), ('*', '*')]
    num1 = TextAreaField('',[validators.DataRequired()])
    num2 = TextAreaField('',[validators.DataRequired()])
    Operator = SelectField(u'', choices = myChoices, validators = [validators.DataRequired()])

# This uses the render_template method in flask to use a template first_app.html. 
# This html contains placeholders for the form that is provided in the kwargs argument to the function call.
@app.route('/')
def index():
    #return 'Hello World!'
    form = OutputForm(request.form)
    return render_template('first_app.html',form = form)

# This is the output that is displayed. It checks if the form is validated and POST request is made. 
# If true it renders the output.html else renders the main index page. 
# Most of the work is done here. Gets the user inputs using the request.form method.
@app.route('/output', methods=['POST'])
def output():
    form = OutputForm(request.form)
    if request.method == 'POST' and form.validate():
        num1 = request.form['num1']
        num2 = request.form['num2']
        op = request.form['Operator']
        if op=="+":
            name=str(int(num1)+int(num2))
        elif op=="-":
            name=str(int(num1)-int(num2))
        elif op=="*":
            name=str(int(num1)*int(num2))
        return render_template('output.html', name=name)
    return render_template('first_app.html', form=form)

if __name__ == '__main__':
    app.run(debug="True")
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;We use WTF forms here to create a form object. We pass this form object to the HTML render_template method. We have accessed these again in the output function so that we can show them in output.html where all the major work is done for creating the app.&lt;/p&gt;
&lt;p&gt;Now Create a folder named template in helloworld/wsgi and create a file named _formhelpers.html with this content. You really don't need to see the content in this file.
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="html"&gt;{% macro render_field(field) %}
    &amp;lt;dt&amp;gt;{{ field.label }}
    &amp;lt;dd&amp;gt;{{ field(**kwargs)|safe }}
    {% if field.errors %}
        &amp;lt;ul class=errors&amp;gt;
        {% for error in field.errors %}
            &amp;lt;li&amp;gt;{{ error }}&amp;lt;/li&amp;gt;
        {% endfor %}
        &amp;lt;/ul&amp;gt;
    {% endif %}
    &amp;lt;/dd&amp;gt;
{% endmacro %} 
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Also add another file named first_app.html with this content. Notice how we access the wtform here.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="html"&gt;&amp;lt;!doctype html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;First app&amp;lt;/title&amp;gt;
&amp;lt;link rel="stylesheet" href="{{ url_for('static',filename='style.css') }}"&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
    {% from "_formhelpers.html" import render_field %}
    &amp;lt;div&amp;gt;Calculator: Please enter two numbers and a function you want to apply&amp;lt;/div&amp;gt;
    &amp;lt;form method=post action="/output"&amp;gt;
    {{ render_field(form.num1) }}{{ render_field(form.Operator) }}{{ render_field(form.num2) }}
        &amp;lt;input type=submit value='Result' name='submit_btn'&amp;gt;
    &amp;lt;/form&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Create a file named output.html where the final output will be shown.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="html"&gt;&amp;lt;!doctype html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;title&amp;gt;First app&amp;lt;/title&amp;gt;
&amp;lt;link rel="stylesheet" href="{{ url_for('static',filename='style.css') }}"&amp;gt;
&amp;lt;/head&amp;gt;
    &amp;lt;body&amp;gt;
        &amp;lt;div&amp;gt;The output is: {{ name }}&amp;lt;/div&amp;gt;
    &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Also add a style.css file in the static folder. You can put this in it for right now or any other thing you want.
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="html"&gt;h1 {
    color: blue;
    font-family: verdana;
    font-size: 300%;
}
p  {
    color: red;
    font-family: courier;
    font-size: 160%;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;  &lt;br /&gt;
And we are mostly done. Run run.py in the wsgi directory and you would be able to access the app at : http://127.0.0.1:5000/.
Again deploy this webapp to Openshift using:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cd helloworld
git add .
git commit -a -m "Initial deployment of this app to the web"
git push
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;Endnotes&lt;/h2&gt;
&lt;p&gt;So here we took inputs from the user and show the output using the flask App. The final app is hosted at http://helloworld-mlwhiz.rhcloud.com/ for you to see. 
This code provides us with a code skeletn which will be valuable when we will deploy a whole ML model, which is the main motive of this series. &lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Most of the code here is taken from this awesome book by Sebastian Raschka: &lt;a rel="nofollow" href="http://www.amazon.com/gp/product/1783555130/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1783555130&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=QOKIQ2S5LIQI7L2N"&gt;Python Machine Learning&lt;/a&gt;&lt;img src="http://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=as2&amp;o=1&amp;a=1783555130" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;&lt;/li&gt;
&lt;li&gt;https://blog.openshift.com/beginners-guide-to-writing-flask-apps-on-openshift/&lt;/li&gt;
&lt;/ol&gt;</summary><category term="FlaskApp"></category><category term="Deploy ML Models"></category><category term="Openshift"></category></entry><entry><title>Shell Basics every Data Scientist Should know - Part II(AWK)</title><link href="http://manishbarnwal.github.io/blog/2015/10/11/shell_basics_for_data_science_2/" rel="alternate"></link><updated>2015-10-11T04:43:00-03:00</updated><author><name>Manish Barnwal</name></author><id>tag:manishbarnwal.github.io,2015-10-11:blog/2015/10/11/shell_basics_for_data_science_2/</id><summary type="html">&lt;p&gt;&lt;div class="entry-content"&gt;&lt;p&gt;Yesterday I got introduced to awk programming on the shell and is it cool. 
It lets you do stuff on the command line which you never imagined. As a matter of fact, it's a whole data analytics software in itself when you think about it. You can do selections, groupby, mean, median, sum, duplication, append. You just ask. There is no limit actually.&lt;/p&gt;
&lt;p&gt;And it is easy to learn.&lt;/p&gt;
&lt;p&gt;In this post, I will try to give you a brief intro about how you could add awk to your daily work-flow.&lt;/p&gt;
&lt;p&gt;Please see my previous &lt;a href="http://mlwhiz.com/blog/2015/10/09/shell_basics_for_data_science/"&gt;post&lt;/a&gt; if you want some background or some basic to intermediate understanding of shell commands.&lt;/p&gt;
&lt;h2&gt;Basics/ Fundamentals&lt;/h2&gt;
&lt;p&gt;So let me start with an example first. Say you wanted to sum a column in a comma delimited file. How would you do that in shell? &lt;/p&gt;
&lt;p&gt;Here is the command. The great thing about awk is that it took me nearly 5 sec to write this command. I did not have to open any text editor to write a python script. &lt;/p&gt;
&lt;p&gt;It lets you do adhoc work quickly.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{ sum=0; FS=","} { sum += $5 } END { print sum }' data.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
44662539172
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;See the command one more time. There is a basic structure to the awk command&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;BEGIN&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;END&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;action&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;An awk program consists of:&lt;/p&gt;

&lt;div class="no-mathjax"  style="margin-left:1em;"&gt;
&lt;li&gt;An optional BEGIN segment : In the begin part we initialize our variables before we even start reading from the file or the standard input.&lt;/li&gt;
&lt;li&gt;pattern - action pairs: In the middle part we Process the input data. You put multiple pattern action pairs when you want to do multiple things with the same line.&lt;/li&gt;
&lt;li&gt;An optional END segment: In the end part we do something we want to do when we have reached the end of file.&lt;/li&gt;
&lt;/div&gt;

&lt;p&gt;An awk command is called on a file using: 
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{SOMETHING HERE} {SOMETHING HERE: could put Multiple Blocks Like this} END {SOMETHING HERE}' file.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;br&gt;
You also need to know about these preinitialized variables that awk keeps track of.:
&lt;div class="no-mathjax"  style="margin-left:2em;"&gt;
&lt;ol&gt;&lt;li&gt;FS : field separator. Default is whitespace (1 or more spaces or tabs). If you are using any other seperator in the file you should specify it in the Begin Part.&lt;/li&gt;
&lt;li&gt;RS : record separator. Default record separator is newline. Can be changed in BEGIN action.&lt;/li&gt;
&lt;li&gt;NR : NR is the variable whose value is the number of the current record. You normally use it in the action blocks in the middle.&lt;/li&gt;
&lt;li&gt;NF : The Number of Fields after the single line has been split up using FS.&lt;/li&gt;
&lt;li&gt;Dollar variables : awk splits up the line which is coming to it by using the given FS and keeps the split parts in the $ variables. For example column 1 is in $1, column 2 is in $2. $0 is the string representation of the whole line. Note that if you want to access last column you don't have to count. You can just use $NF. For second last column you can use $(NF-1). Pretty handy. Right.&lt;/li&gt;&lt;/ol&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;So If you are with me till here, the hard part is done. Now the fun part starts. Lets look at the first awk command again and try to understand it.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{ sum=0; FS=","} { sum += $5 } END { print sum }' data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;So there is a begin block. Remember before we read any line. We initialize sum to 0 and FS to ",".&lt;/p&gt;
&lt;div class="no-mathjax"&gt;
Now as awk reads its input line by line it increments sum by the value in column 5(as specified by $5). 
&lt;/div&gt;

&lt;p&gt;Note that there is no pattern specified here so awk will do the action for every line. &lt;/p&gt;
&lt;p&gt;When awk has completed reading the file it prints out the sum.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What if you wanted mean?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We could create a cnt Variable:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{ sum=0;cnt=0; FS=","} { sum += $5; cnt+=1 } END { print sum/cnt }' data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
1.86436e+06
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
or better yet, use our friend NR which bash is alreay keeping track of:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{ sum=0; FS=","} { sum += $5 } END { print sum/NR }' data.txt
&lt;/code&gt;&lt;/pre&gt;
&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
1.86436e+06
&lt;/pre&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;Filter a file&lt;/h2&gt;
&lt;p&gt;In the mean and sum awk commands we did not put any pattern in our middle commands. Let us use a simple pattern now. Suppose we have a file Salaries.csv which contains:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;head salaries.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID,teamID,lgID,playerID,salary
1985,BAL,AL,murraed02,1472819
1985,BAL,AL,lynnfr01,1090000
1985,BAL,AL,ripkeca01,800000
1985,BAL,AL,lacyle01,725000
1985,BAL,AL,flanami01,641667
1985,BAL,AL,boddimi01,625000
1985,BAL,AL,stewasa01,581250
1985,BAL,AL,martide01,560000
1985,BAL,AL,roeniga01,558333
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
I want to filter records for players who who earn more than 22 M in 2013 just because I want to. You just do:
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{FS=","} $5&amp;gt;=22000000 &amp;amp;&amp;amp; $1==2013{print $0}' Salaries.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
2013,DET,AL,fieldpr01,23000000
2013,MIN,AL,mauerjo01,23000000
2013,NYA,AL,rodrial01,29000000
2013,NYA,AL,wellsve01,24642857
2013,NYA,AL,sabatcc01,24285714
2013,NYA,AL,teixema01,23125000
2013,PHI,NL,leecl02,25000000
2013,SFN,NL,linceti01,22250000
&lt;/pre&gt;
&lt;br&gt;
&lt;div class="no-mathjax"&gt;
Cool right. Now let me explain it a little bit. The part in the command "$5&amp;gt;=22000000 &amp;amp;&amp;amp; $1==2013" is called a pattern. It says that print this line($0) if and only if the Salary($5) is more than 22M and(&amp;amp;&amp;amp;) year($1) is equal to 2013. If the incoming record(line) does not satisfy this pattern it never reaches the inner block. 
&lt;/div&gt;
So Now you could do basic Select SQL at the command line only if you had:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The logic Operators:&lt;/strong&gt;
&lt;div class="no-mathjax"  style="margin-left:1em;"&gt;
&lt;li&gt;  == equality operator; returns TRUE is both sides are equal&lt;/li&gt;
&lt;li&gt; != inverse equality operator&lt;/li&gt;
&lt;li&gt; &amp;amp;&amp;amp; logical AND&lt;/li&gt;
&lt;li&gt; || logical OR&lt;/li&gt;
&lt;li&gt; ! logical NOT&lt;/li&gt;
&lt;li&gt; &amp;lt;, &amp;gt;, &amp;lt;=, &amp;gt;= relational operators&lt;/li&gt;
&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Normal Arithmetic Operators:&lt;/strong&gt; +, -, /, *, %, ^&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Some String Functions:&lt;/strong&gt; length, substr, split&lt;/p&gt;
&lt;h2&gt;GroupBy&lt;/h2&gt;
&lt;p&gt;Now you will say: "Hey Dude SQL without groupby is incomplete". You are right and for that we can use the associative array. Lets just see the command first and then I will explain. So lets create another useless use case(or may be something useful to someone :))
We want to find out the number of records for each year in the file. i.e we want to find the distribution of years in the file. Here is the command:&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;awk 'BEGIN{FS=","}
{my_array[$1]=my_array[$1]+1}
END{
for (k in my_array){if(k!="yearID")print k"|"my_array[k]};
}' Salaries.csv
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
1990|867
1991|685
1996|931
1997|925
...
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
Now I would like to tell you a secret. You don't really need to declare the variables you want to use in awk. So you did not really needed to define sum, cnt variables before. I only did that because it is good practice. If you don't declare a user defined variable in awk, awk assumes it to be null or zero depending on the context. So in the command above we don't declare our myarray in the begin block and that is fine.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Associative Array&lt;/strong&gt;: The variable myarray is actually an associative array. i.e. It stores data in a key value format.(Python dictionaries anyone). The same array could keep integer keys and String keys. For example, I can do this in a single code.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;myarray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;key&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;myarray&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;mlwhiz&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;For Loop for associative arrays&lt;/strong&gt;: I could use a for loop to read associative array&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="n"&gt;DO&lt;/span&gt; &lt;span class="n"&gt;SOMETHING&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="cp"&gt;# Assigns to k each Key of array (unordered)&lt;/span&gt;
&lt;span class="cp"&gt;# Element is array[k]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;If Statement&lt;/strong&gt;:Uses a syntax like C for the if statement. the else block is optional: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="n"&gt;DO&lt;/span&gt; &lt;span class="n"&gt;SOMETHING&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
  &lt;span class="n"&gt;DO&lt;/span&gt; &lt;span class="n"&gt;SOMETHING&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So lets dissect the above command now.&lt;/p&gt;
&lt;p&gt;I set the File separator to "," in the beginning. I use the first column as the key of myarray. If the key exists I increment the value by 1.&lt;/p&gt;
&lt;p&gt;At the end, I loop through all the keys and print out key value pairs separated by "|"&lt;/p&gt;
&lt;p&gt;I know that the header line in my file contains "yearID" in column 1 and I don't want 'yearID|1' in the output. So I only print when Key is not equal to 'yearID'.&lt;/p&gt;
&lt;h2&gt;GroupBy with case statement:&lt;/h2&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat Salaries.csv | awk 'BEGIN{FS=","}
$5&lt;100000{array5["[0-100000)"]+=1}
$5&gt;=100000&amp;&amp;$5&lt;250000{array5["[100000,250000)"]=array5["[100000,250000)"]+1}
$5&gt;=250000&amp;&amp;$5&lt;500000{array5["[250000-500000)"]=array5["[250000-500000)"]+1}
$5&gt;=500000&amp;&amp;$5&lt;1000000{array5["[500000-1000000)"]=array5["[500000-1000000)"]+1}
$5&gt;=1000000{array5["[1000000)"]=array5["[1000000)"]+1}
END{
print "VAR Distrib:";
for (v in array5){print v"|"array5[v]}
}'
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
VAR Distrib:
[250000-500000)|8326
[0-100000)|2
[1000000)|23661
[100000,250000)|9480
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
Here we used multiple pattern-action blocks to create a case statement.&lt;/p&gt;
&lt;h2&gt;For The Brave:&lt;/h2&gt;
&lt;p&gt;This is a awk code that I wrote to calculate the Mean,Median,min,max and sum of a column simultaneously. Try to go through the code and understand it.I have added comments too.
Think of this as an exercise. Try to run this code and play with it. You may learn some new tricks in the process.
If you don't understand it do not worry. Just get started writing your own awk codes, you will be able to understand it in very little time.&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;# Create a New file named A.txt to keep only the salary column.
cat Salaries.csv | cut -d "," -f 5 &gt; A.txt
FILENAME="A.txt"

# The first awk counts the number of lines which are numeric. We use a regex here to check if the column is numeric or not.
# ';' stands for Synchronous execution i.e sort only runs after the awk is over. 
# The output of both commands are given to awk command which does the whole work.
# So Now the first line going to the second awk is the number of lines in the file which are numeric.
# and from the second to the end line the file is sorted.
(awk 'BEGIN {c=0} $1 ~ /^[-0-9]*(\.[0-9]*)?$/ {c=c+1;} END {print c;}' "$FILENAME"; \
        sort -n "$FILENAME") | awk '
  BEGIN {
    c = 0;
    sum = 0;
    med1_loc = 0;
    med2_loc = 0;
    med1_val = 0;
    med2_val = 0;
    min = 0;
    max = 0;
  }

  NR==1 {
    LINES = $1
    # We check whether numlines is even or odd so that we keep only
    # the locations in the array where the median might be.
    if (LINES%2==0) {med1_loc = LINES/2-1; med2_loc = med1_loc+1;}
    if (LINES%2!=0) {med1_loc = med2_loc = (LINES-1)/2;}
  }

  $1 ~ /^[-0-9]*(\.[0-9]*)?$/  &amp;&amp;  NR!=1 {
    # setting min value
    if (c==0) {min = $1;}
    # middle two values in array
    if (c==med1_loc) {med1_val = $1;}
    if (c==med2_loc) {med2_val = $1;}
    c++
    sum += $1
    max = $1
  }
  END {
    ave = sum / c
    median = (med1_val + med2_val ) / 2
    print "sum:" sum
    print "count:" c
    print "mean:" ave
    print "median:" median
    print "min:" min
    print "max:" max
  }
'
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
sum:44662539172
count:23956
mean:1.86436e+06
median:507950
min:0
max:33000000
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;h2&gt;Endnote:&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;awk&lt;/strong&gt; is an awesome tool and there are a lot of use-cases where it can make your life simple. There is a sort of a learning curve, but I think that it would be worth it in the long term. I have tried to give you a taste of awk and I have covered a lot of ground here in this post. To tell you a bit more there, awk is a full programming language. There are for loops, while loops, conditionals, booleans, functions and everything else that you would expect from a programming language. So you could look more still. &lt;/p&gt;
&lt;p&gt;To learn more about awk you can use this &lt;a href="http://ir.nmu.org.ua/bitstream/handle/123456789/143548/ecf2f2d8a72e7c3cffca0036a73aeed4.pdf?sequence=1&amp;amp;"&gt;book&lt;/a&gt;. This book is a free resource and you could learn more about awk and use cases.&lt;/p&gt;
&lt;p&gt;Or if you like to have your book binded and in paper like me you can buy this book, which is a gem:&lt;/p&gt;
&lt;div style="text-align: center;"&gt;
&lt;a href="http://www.amazon.com/gp/product/1565922255/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1565922255&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=YC37WW67AJHS3T6S"&gt;&lt;img border="0" src="http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1565922255&amp;Format=_SL250_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="http://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=as2&amp;o=1&amp;a=1565922255" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;" /&gt;
&lt;/div&gt;

&lt;p&gt;Do leave comments in case you find more use-cases for awk or if you want me to write on new use-cases. Or just comment weather you liked it or not and how I could improve as I am also new and trying to learn more of this.&lt;/p&gt;
&lt;p&gt;Till then Ciao !!!&lt;/p&gt;&lt;/div&gt;</summary><category term="bash commands"></category><category term="bash for data science"></category></entry><entry><title>Shell Basics every Data Scientist Should know -Part I</title><link href="http://manishbarnwal.github.io/blog/2015/10/09/shell_basics_for_data_science/" rel="alternate"></link><updated>2015-10-09T04:43:00-03:00</updated><author><name>Manish Barnwal</name></author><id>tag:manishbarnwal.github.io,2015-10-09:blog/2015/10/09/shell_basics_for_data_science/</id><summary type="html">&lt;p&gt;&lt;div class="entry-content"&gt;&lt;p&gt;Shell Commands are powerful. And life would be like &lt;strong&gt;hell without shell&lt;/strong&gt; is how I like to say it(And that is probably the reason that I dislike windows).&lt;/p&gt;
&lt;p&gt;Consider a case when you have a 6 GB pipe-delimited file sitting on your laptop and you want to find out the count of distinct values in one particular column. You can probably do this in more than one way. You could put that file in a database and run SQL Commands, or you could write a python/perl script.&lt;/p&gt;
&lt;p&gt;Probably whatever you do it won't be simpler/less time consuming than this&lt;/p&gt;
&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | cut -d "|" -f 1 | sort | uniq | wc -l
&lt;/code&gt;&lt;/pre&gt;
&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;30
&lt;/pre&gt;&lt;/p&gt;
&lt;p&gt;And this will &lt;strong&gt;run way faster&lt;/strong&gt; than whatever you do with perl/python script.&lt;/p&gt;

&lt;p&gt;Now this command says:
&lt;div style="margin-left:1em;"&gt;
&lt;ul&gt;
&lt;li&gt; Use the &lt;strong&gt;cat&lt;/strong&gt; command to print/stream the contents of the file to stdout.&lt;/li&gt;
&lt;li&gt; Pipe the streaming contents from our cat command to the next command &lt;strong&gt;cut&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt; The &lt;strong&gt;cut&lt;/strong&gt; commands specifies the delimiter by the argument &lt;strong&gt;-d&lt;/strong&gt; and the column by the argument &lt;strong&gt;-f&lt;/strong&gt; and streams the output to stdout.&lt;/li&gt;
&lt;li&gt; Pipe the streaming content to the &lt;strong&gt;sort&lt;/strong&gt; command which sorts the input and streams only the distinct values to the stdout. It takes the argument &lt;strong&gt;-u&lt;/strong&gt; that specifies that we only need unique values.&lt;/li&gt;
&lt;li&gt; Pipe the output to the wc -l  command which counts the number of lines in the input.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;There is a &lt;strong&gt;lot going on here&lt;/strong&gt; and I will try my best to ensure that &lt;strong&gt;you will be able to understand most of it by the end of this Blog post&lt;/strong&gt;.Although I will also try to explain more advanced concepts than the above command in this post.&lt;/p&gt;

&lt;p&gt;Now, I use shell commands extensively at my job. I will try to explain the usage of each of the commands based on use cases that I counter nearly daily at may day job as a data scientist.&lt;/p&gt;

&lt;h2&gt;Some Basic Commands in Shell:&lt;/h2&gt;

&lt;p&gt;There are a lot of times when you just need to know a little bit about the data. You just want to see may be a couple of lines to inspect a file. One way of doing this is opening the txt/csv file in the notepad. And that is probably the best way for small files. But you could also do it in the shell using:&lt;/p&gt;

&lt;h2&gt;1. cat&lt;/h2&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID|teamID|lgID|playerID|salary
1985|BAL|AL|murraed02|1472819
1985|BAL|AL|lynnfr01|1090000
1985|BAL|AL|ripkeca01|800000
1985|BAL|AL|lacyle01|725000
1985|BAL|AL|flanami01|641667
1985|BAL|AL|boddimi01|625000
1985|BAL|AL|stewasa01|581250
1985|BAL|AL|martide01|560000
1985|BAL|AL|roeniga01|558333
&lt;/pre&gt;

&lt;p&gt;Now the &lt;a href="https://en.wikipedia.org/wiki/Cat_%28Unix%29"&gt;cat&lt;/a&gt; command prints the whole file in the terminal window for you.I have not shown the whole file here.&lt;/p&gt;

&lt;p&gt;But sometimes the files will be so big that you wont be able to open them up in notepad++ or any other software utility and there the cat command will shine.&lt;/p&gt;

&lt;h2&gt;2. Head and Tail&lt;/h2&gt;

&lt;p&gt;Now you might ask me why would you print the whole file in the terminal itself? Generally I won't. But I just wanted to tell you about the cat command. For the use case when you want only the top/bottom n lines of your data you will generally use the &lt;a href="https://en.wikipedia.org/wiki/Head_%28Unix%29"&gt;head&lt;/a&gt;/&lt;a href="https://en.wikipedia.org/wiki/Tail_%28Unix%29"&gt;tail&lt;/a&gt; commands. You can use them as below.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;head data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID|teamID|lgID|playerID|salary
1985|BAL|AL|murraed02|1472819
1985|BAL|AL|lynnfr01|1090000
1985|BAL|AL|ripkeca01|800000
1985|BAL|AL|lacyle01|725000
1985|BAL|AL|flanami01|641667
1985|BAL|AL|boddimi01|625000
1985|BAL|AL|stewasa01|581250
1985|BAL|AL|martide01|560000
1985|BAL|AL|roeniga01|558333
&lt;/pre&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;head -n 3 data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID|teamID|lgID|playerID|salary
1985|BAL|AL|murraed02|1472819
1985|BAL|AL|lynnfr01|1090000
&lt;/pre&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;tail data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
2013|WAS|NL|bernaro01|1212500
2013|WAS|NL|tracych01|1000000
2013|WAS|NL|stammcr01|875000
2013|WAS|NL|dukeza01|700000
2013|WAS|NL|espinda01|526250
2013|WAS|NL|matthry01|504500
2013|WAS|NL|lombast02|501250
2013|WAS|NL|ramoswi01|501250
2013|WAS|NL|rodrihe03|501000
2013|WAS|NL|moorety01|493000
&lt;/pre&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;tail -n 2 data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
2013|WAS|NL|rodrihe03|501000
2013|WAS|NL|moorety01|493000
&lt;/pre&gt;

&lt;p&gt;Notice the structure of the shell command here. &lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;CommandName&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;arg1name&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;arg1value&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;arg2name&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;arg2value&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;3. Piping&lt;/h2&gt;

&lt;p&gt;Now we could have also written the same command as:&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | head 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID|teamID|lgID|playerID|salary
1985|BAL|AL|murraed02|1472819
1985|BAL|AL|lynnfr01|1090000
1985|BAL|AL|ripkeca01|800000
1985|BAL|AL|lacyle01|725000
1985|BAL|AL|flanami01|641667
1985|BAL|AL|boddimi01|625000
1985|BAL|AL|stewasa01|581250
1985|BAL|AL|martide01|560000
1985|BAL|AL|roeniga01|558333
&lt;/pre&gt;

&lt;p&gt;This brings me to one of the most important concepts of Shell usage - &lt;a href="https://en.wikipedia.org/wiki/Pipeline_%28Unix%29"&gt;&lt;strong&gt;piping&lt;/strong&gt;&lt;/a&gt;.
You won't be able to utilize the full power the shell provides without using this concept.
And the concept is actually simple.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Just read the "|" in the command as "pass the data on to"&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;So I would read the above command as:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;cat&lt;/em&gt;(print) the whole data to stream, &lt;strong&gt;pass the data on to&lt;/strong&gt; &lt;em&gt;head&lt;/em&gt; so that it can just give me the first few lines only.&lt;/p&gt;

&lt;p&gt;So did you understood what piping did? &lt;strong&gt;It is providing us a way to use our basic commands in a consecutive manner&lt;/strong&gt;. There are a lot of commands that are fairly basic and it lets us use these basic commands in sequence to do some fairly non trivial things.&lt;/p&gt;

&lt;p&gt;Now let me tell you about a couple of more commands before I show you how we can &lt;strong&gt;chain&lt;/strong&gt; them to do fairly advanced tasks.&lt;/p&gt;

&lt;h2&gt;4. wc&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Wc_%28Unix%29"&gt;wc&lt;/a&gt; is a fairly useful shell utility/command that lets us &lt;strong&gt;count the number of lines(-l)&lt;/strong&gt;, &lt;strong&gt;words(-w)&lt;/strong&gt; or &lt;strong&gt;characters(-c)&lt;/strong&gt; in a given file&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;wc -l data.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
23957 data.txt   
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2&gt;5. grep&lt;/h2&gt;

&lt;p&gt;You may want to print all the lines in your file which have a particular word. Or as a Data case you might like to see the salaries for the team BAL in 2000. In this case we have printed all the lines in the file which contain "2000|BAL". &lt;a href="https://en.wikipedia.org/wiki/Grep"&gt;grep&lt;/a&gt; is your friend.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;grep "2000|BAL" data.txt | head
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
2000|BAL|AL|belleal01|12868670
2000|BAL|AL|anderbr01|7127199
2000|BAL|AL|mussimi01|6786032
2000|BAL|AL|ericksc01|6620921
2000|BAL|AL|ripkeca01|6300000
2000|BAL|AL|clarkwi02|6000000
2000|BAL|AL|johnsch04|4600000
2000|BAL|AL|timlimi01|4250000
2000|BAL|AL|deshide01|4209324
2000|BAL|AL|surhobj01|4146789
&lt;/pre&gt;

&lt;p&gt;you could also use regular expressions with grep. &lt;/p&gt;

&lt;h2&gt;6. sort&lt;/h2&gt;

&lt;p&gt;You may want to &lt;a href="https://en.wikipedia.org/wiki/Sort_%28Unix%29"&gt;sort&lt;/a&gt; your dataset on a particular column.Sort is your friend. 
Say you want to find out the top 10 maximum salaries given to any player in your dataset.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;sort -t "|" -k 5 -r -n data.txt | head -10
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
2010|NYA|AL|rodrial01|33000000
2009|NYA|AL|rodrial01|33000000
2011|NYA|AL|rodrial01|32000000
2012|NYA|AL|rodrial01|30000000
2013|NYA|AL|rodrial01|29000000
2008|NYA|AL|rodrial01|28000000
2011|LAA|AL|wellsve01|26187500
2005|NYA|AL|rodrial01|26000000
2013|PHI|NL|leecl02|25000000
2013|NYA|AL|wellsve01|24642857
&lt;/pre&gt;

&lt;p&gt;So there are certainly a lot of options in this command. Lets go through them one by one.&lt;/p&gt;

&lt;div style="margin-left:1em"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;-t&lt;/strong&gt;: Which delimiter to use?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-k&lt;/strong&gt;: Which column to sort on?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-n&lt;/strong&gt;: If you want Numerical Sorting. Dont use this option if you want Lexographical sorting.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-r&lt;/strong&gt;: I want to sort Descending. Sorts Ascending by Default.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;h2&gt;7. cut&lt;/h2&gt;

&lt;p&gt;This command lets you select certain columns from your data. Sometimes you may want to look at just some of the columns in your data. As in you may want to look only at the year, team and salary and not the other columns. &lt;a href="https://en.wikipedia.org/wiki/Cut_(Unix)"&gt;cut&lt;/a&gt; is the command to use.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cut -d "|" -f 1,2,5 data.txt | head
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID|teamID|salary
1985|BAL|1472819
1985|BAL|1090000
1985|BAL|800000
1985|BAL|725000
1985|BAL|641667
1985|BAL|625000
1985|BAL|581250
1985|BAL|560000
1985|BAL|558333
&lt;/pre&gt;

&lt;p&gt;The options are:
&lt;div style="margin-left:1em"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;-d&lt;/strong&gt;: Which delimiter to use?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;-f&lt;/strong&gt;: Which column/columns to cut?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;&lt;/p&gt;

&lt;h2&gt;8. uniq&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Uniq"&gt;uniq&lt;/a&gt; is a little bit tricky as in you will want to use this command in sequence with sort. This command removes sequential duplicates. So in conjunction with sort it can be used to get the distinct values in the data. For example if I wanted to find out 10 distinct teamIDs in data, I would use:&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | cut -d "|" -f 2 | sort | uniq | head
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
ANA
ARI
ATL
BAL
BOS
CAL
CHA
CHN
CIN
CLE
&lt;/pre&gt;

&lt;p&gt;This command could be used with argument &lt;strong&gt;-c&lt;/strong&gt; to count the occurrence of these distinct values. Something akin to &lt;strong&gt;count distinct&lt;/strong&gt;.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | cut -d "|" -f 2 | sort | uniq -c | head
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
247 ANA
458 ARI
838 ATL
855 BAL
852 BOS
368 CAL
812 CHA
821 CHN
46 CIN
867 CLE
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2&gt;Some Other Utility Commands for Other Operations&lt;/h2&gt;

&lt;p&gt;Some Other command line tools that you could use without going in the specifics as the specifics are pretty hard.&lt;/p&gt;

&lt;h2&gt;1. Change delimiter in a file&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Find and Replace Magic.&lt;/strong&gt;: You may want to replace certain characters in file with something else using the &lt;a href="https://en.wikipedia.org/wiki/Tr_%28Unix%29"&gt;tr&lt;/a&gt; command.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | tr '|' ',' |  head -4
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID,teamID,lgID,playerID,salary
1985,BAL,AL,murraed02,1472819
1985,BAL,AL,lynnfr01,1090000
1985,BAL,AL,ripkeca01,800000
&lt;/pre&gt;

&lt;p&gt;or the &lt;a href="https://en.wikipedia.org/wiki/Sed"&gt;&lt;strong&gt;sed&lt;/strong&gt;&lt;/a&gt; command&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | sed -e 's/|/,/g' | head -4
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
yearID,teamID,lgID,playerID,salary
1985,BAL,AL,murraed02,1472819
1985,BAL,AL,lynnfr01,1090000
1985,BAL,AL,ripkeca01,800000
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2&gt;2. Sum of a column in a file&lt;/h2&gt;

&lt;p&gt;Using the &lt;a href="https://en.wikipedia.org/wiki/AWK"&gt;awk&lt;/a&gt; command you could find the sum of column in file. Divide it by the number of lines and you can get the mean.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | awk -F "|" '{ sum += $5 } END { printf sum }'
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
44662539172
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
awk is a powerful command which is sort of a whole language in itself. Do see the wiki page for &lt;a href="https://en.wikipedia.org/wiki/AWK"&gt;awk&lt;/a&gt; for a lot of great usecases of awk. I also wrote a post on awk as a second part in this series. Check it &lt;a href="http://mlwhiz.com/blog/2015/10/11/shell_basics_for_data_science_2/"&gt;HERE&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;3. Find the files in a directory that satisfy a certain condition&lt;/h2&gt;

&lt;p&gt;You can do this by using the find command. Lets say you want to &lt;strong&gt;find all the .txt files&lt;/strong&gt; in the current working dir that &lt;strong&gt;start with lowercase h&lt;/strong&gt;.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;find . -name "h*.txt" 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
./hamlet.txt
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;To find &lt;strong&gt;all .txt files starting with h regarless of case&lt;/strong&gt; we could use regex.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;find . -name "[Hh]*.txt" 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
./hamlet.txt
./Hamlet1.txt
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;h2&gt;4. Passing file list as Argument.&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Xargs"&gt;xargs&lt;/a&gt; was suggested by Gaurav in the comments, so I read about it and it is actually a very nice command which you could use in a variety of use cases.&lt;/p&gt;

&lt;p&gt;So if you just use a pipe, any command/utility receives data on STDIN (the standard input stream) as a raw pile of data that it can sort through one line at a time. However some programs don't accept their commands on standard in. For example the rm command(which is used to remove files), touch command(used to create file with a given name) or a certain python script you wrote(which takes command line arguments). They expect it to be spelled out in the arguments to the command. 
&lt;br&gt;&lt;/p&gt;

&lt;p&gt;For example: 
rm takes a file name as a parameter on the command line like so: rm file1.txt.
If I wanted to &lt;strong&gt;delete all '.txt' files starting with "h/H"&lt;/strong&gt; from my working directory, the below command won't work because rm expects a file as an input.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;find . -name "[hH]*.txt" | rm 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
usage: rm [-f | -i] [-dPRrvW] file ...
unlink file
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;To get around it we can use the xargs command which reads the STDIN stream data and converts each line into space separated arguments to the command.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;find . -name "[hH]*.txt" | xargs
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
./hamlet.txt ./Hamlet1.txt
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Now you could use rm to remove all .txt files that start with h/H. A word of advice: Always see the output of xargs first before using rm.&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;find . -name "[hH]*.txt" | xargs rm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Another usage of xargs could be in conjunction with grep to &lt;strong&gt;find all files that contain a given string&lt;/strong&gt;. &lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;find . -name "*.txt" | xargs grep 'honest soldier'
&lt;/code&gt;&lt;/pre&gt;

&lt;pre style="font-size:50%; padding:7px; margin:0em;  background-color:#F5F5F5"&gt;
./Data1.txt:O, farewell, honest soldier;
./Data2.txt:O, farewell, honest soldier;
./Data3.txt:O, farewell, honest soldier;
&lt;/pre&gt;

&lt;p&gt;&lt;br&gt;
Hopefully You could come up with varied uses building up on these examples. One other use case could be to use this for &lt;strong&gt;passing arguments to a python script&lt;/strong&gt;.
&lt;br&gt;&lt;/p&gt;

&lt;h2&gt;Other Cool Tricks&lt;/h2&gt;

&lt;p&gt;Sometimes you want your data that you got by some command line utility(Shell commands/ Python scripts) not to be shown on stdout but stored in a textfile. You can use the &lt;strong&gt;"&amp;gt;"&lt;/strong&gt; operator for that. For Example: You could have stored the file after replacing the delimiters in the previous example into anther file called newdata.txt as follows:&lt;/p&gt;

&lt;pre style="font-size:60%; padding:7px; margin:0em;"&gt;
&lt;code class="bash"&gt;cat data.txt | tr '|' ',' &gt; newdata.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I really got confused between &lt;strong&gt;"|"&lt;/strong&gt; (piping) and &lt;strong&gt;"&amp;gt;"&lt;/strong&gt; (to_file) operations a lot in the beginning. One way to remember is that you should only use &lt;strong&gt;"&amp;gt;"&lt;/strong&gt; when you want to write something to a file. &lt;strong&gt;"|" cannot be used to write to a file.&lt;/strong&gt;
Another operation you should know about is the &lt;strong&gt;"&amp;gt;&amp;gt;"&lt;/strong&gt; operation. It is analogous to &lt;strong&gt;"&amp;gt;"&lt;/strong&gt; but it appends to an existing file rather that replacing the file and writing over.&lt;/p&gt;

&lt;p&gt;If you would like to know more about commandline, which I guess you would, here are some books that I would recommend for a beginner:&lt;/p&gt;

&lt;div style="margin-left:1em ; text-align: center;"&gt;

&lt;a href="http://www.amazon.com/gp/product/1593273894/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1593273894&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=IXZOHV6FHPTYCBCT"&gt;&lt;img border="0" src="http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1593273894&amp;Format=_SL250_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="http://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=as2&amp;o=1&amp;a=1593273894" width="1" height="1" border="0" alt="" style="border:none !important; margin:80px !important;" /&gt;
&lt;/t&gt;&lt;/t&gt;
&lt;a href="http://www.amazon.com/gp/product/0596009658/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0596009658&amp;linkCode=as2&amp;tag=mlwhizcon-20&amp;linkId=2ZHHZIAJBFW3BFF7"&gt;&lt;img border="0" src="http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=0596009658&amp;Format=_SL250_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=mlwhizcon-20" &gt;&lt;/a&gt;&lt;img src="http://ir-na.amazon-adsystem.com/e/ir?t=mlwhizcon-20&amp;l=as2&amp;o=1&amp;a=0596009658" width="1" height="1" border="0" alt="" style="border:none !important; margin:30px !important;" /&gt;

&lt;/div&gt;

&lt;p&gt;The first book is more of a fun read at leisure type of book. THe second book is a little more serious. Whatever suits you. &lt;/p&gt;

&lt;p&gt;So, this is just the tip of the iceberg. Although I am not an expert in shell usage, these commands reduced my workload to a large extent. 
If there are some shell commands you use on a regular basis or some shell command that are cool, do tell in the comments. 
I would love to include it in the blogpost.&lt;/p&gt;

&lt;p&gt;I wrote a blogpost on awk as a second part of this post. Check it &lt;a href="http://mlwhiz.com/blog/2015/10/11/shell_basics_for_data_science_2/"&gt;Here&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;</summary><category term="bash commands"></category><category term="bash for data science"></category></entry><entry><title>Create basic graph visualizations with SeaBorn- The Most Awesome Python Library For Visualization yet</title><link href="http://manishbarnwal.github.io/blog/2015/09/13/seaborn_visualizations/" rel="alternate"></link><updated>2015-09-13T04:43:00-03:00</updated><author><name>Manish Barnwal</name></author><id>tag:manishbarnwal.github.io,2015-09-13:blog/2015/09/13/seaborn_visualizations/</id><summary type="html">&lt;p&gt;When it comes to data preparation and getting acquainted with data, the &lt;strong&gt;one step we normally skip is the data visualization&lt;/strong&gt;. 
While a part of it could be attributed to the &lt;strong&gt;lack of good visualization tools&lt;/strong&gt; for the platforms we use, most of us also &lt;strong&gt;get lazy&lt;/strong&gt; at times.&lt;/p&gt;
&lt;p&gt;Now as we know of it Python never had any good Visualization library. For most of our plotting needs, I would read up blogs, hack up with StackOverflow solutions and haggle with &lt;a href="http://matplotlib.org/"&gt;Matplotlib&lt;/a&gt; documentation each and every time I needed to make a simple graph. This led me to think that a &lt;strong&gt;Blog post to create common Graph types&lt;/strong&gt; in Python is in order. But being the procrastinator that I am it always got pushed to the back of my head. &lt;/p&gt;
&lt;p&gt;But, yesterday I got introduced to &lt;a href="http://stanford.edu/~mwaskom/software/seaborn/"&gt;&lt;strong&gt;Seaborn&lt;/strong&gt;&lt;/a&gt; and I must say I am &lt;strong&gt;quite impressed&lt;/strong&gt; with it. It makes &lt;strong&gt;beautiful graphs&lt;/strong&gt; that are in my opinion &lt;strong&gt;better than R's &lt;a href="http://ggplot2.org/"&gt;ggplot2&lt;/a&gt;&lt;/strong&gt;. Gives you enough options to &lt;strong&gt;customize&lt;/strong&gt; and the best part is that it is so &lt;strong&gt;easy to learn&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;So I am finally writing this blog post with a basic &lt;strong&gt;purpose of creating a code base&lt;/strong&gt; that provides me with ready to use codes which could be put into analysis in a fairly straight-forward manner.&lt;/p&gt;
&lt;p&gt;Right. So here Goes.&lt;/p&gt;
&lt;p&gt;We Start by importing the libraries that we will need to use.&lt;/p&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;import matplotlib.pyplot as plt  #sets up plotting under plt
import seaborn as sns           #sets up styles and gives us more plotting options
import pandas as pd             #lets us handle data as dataframes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To create a use case for our graphs, we will be working with the &lt;strong&gt;Tips data&lt;/strong&gt; that contains the following information.&lt;/p&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;tips = sns.load_dataset("tips")
tips.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/tips.png"  height="400" width="500" &gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2&gt;Scatterplot With Regression Line&lt;/h2&gt;
&lt;p&gt;Now let us work on visualizing this data.
We will use the &lt;a href="http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.regplot.html#seaborn.regplot"&gt;&lt;strong&gt;regplot&lt;/strong&gt;&lt;/a&gt; option in seaborn. &lt;/p&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# We dont Probably need the Gridlines. Do we? If yes comment this line
sns.set(style="ticks")

# Here we create a matplotlib axes object. The extra parameters we use 
# "ci" to remove confidence interval
# "marker" to have a x as marker. 
# "scatter_kws" to provide style info for the points.[s for size]
# "line_kws" to provide style info for the line.[lw for line width]

g = sns.regplot(x="tip", y="total_bill", data=tips, ci = False, 
    scatter_kws={"color":"darkred","alpha":0.3,"s":90},
    line_kws={"color":"g","alpha":0.5,"lw":4},marker="x")

# remove the top and right line in graph
sns.despine()

# Set the size of the graph from here
g.figure.set_size_inches(12,8)
# Set the Title of the graph from here
g.axes.set_title('Total Bill vs. Tip', fontsize=34,color="r",alpha=0.5)
# Set the xlabel of the graph from here
g.set_xlabel("Tip",size = 67,color="r",alpha=0.5)
# Set the ylabel of the graph from here
g.set_ylabel("Total Bill",size = 67,color="r",alpha=0.5)
# Set the ticklabel size and color of the graph from here
g.tick_params(labelsize=14,labelcolor="black")
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/regplot.png"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Now that required a bit of a code but i feel that it &lt;strong&gt;looks much better than what either Matplotlib or ggPlot2 could have rendered&lt;/strong&gt;. We got a lot of customization without too much code.&lt;/p&gt;
&lt;p&gt;But that is not really what actually made me like Seaborn. The plot type that actually got my attention was &lt;a href="http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.lmplot.html#seaborn.lmplot"&gt;&lt;strong&gt;lmplot&lt;/strong&gt;&lt;/a&gt;, which lets us use &lt;strong&gt;regplot&lt;/strong&gt; in a &lt;strong&gt;faceted&lt;/strong&gt; mode.&lt;/p&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# So this function creates a faceted plot. The plot is parameterized by the following:

# col : divides the data points into days and creates that many plots
# palette: deep, muted, pastel, bright, dark, and colorblind. change the colors in graph. Experiment with these
# col_wrap: we want 2 graphs in a row? Yes.We do
# scatter_kws: attributes for points
# hue: Colors on a particular column.
# size: controls the size of graph

g = sns.lmplot(x="tip", y="total_bill",ci=None,data=tips, col="day",
    palette="muted",col_wrap=2,scatter_kws={"s": 100,"alpha":.5},
    line_kws={"lw":4,"alpha":0.5},hue="day",x_jitter=1.0,y_jitter=1.0,size=6)

# remove the top and right line in graph
sns.despine()
# Additional line to adjust some appearance issue
plt.subplots_adjust(top=0.9)

# Set the Title of the graph from here
g.fig.suptitle('Total Bill vs. Tip', fontsize=34,color="r",alpha=0.5)

# Set the xlabel of the graph from here
g.set_xlabels("Tip",size = 50,color="r",alpha=0.5)

# Set the ylabel of the graph from here
g.set_ylabels("Total Bill",size = 50,color="r",alpha=0.5)

# Set the ticklabel size and color of the graph from here
titles = ['Thursday','Friday','Saturday','Sunday']
for ax,title in zip(g.axes.flat,titles):
    ax.tick_params(labelsize=14,labelcolor="black")
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/lmplot.png"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;div style="color:black; background-color: #E9DAEE;"&gt;
&lt;a href="http://stanford.edu/~mwaskom/software/seaborn/tutorial/color_palettes.html#building-color-palettes-with-color-palette"&gt;&lt;strong&gt;A side Note on Palettes&lt;/strong&gt;&lt;/a&gt;:&lt;br&gt; 
You can build your own color palettes using &lt;strong&gt;color_palette()&lt;/strong&gt; function.
color_palette() will accept the name of any &lt;strong&gt;seaborn palette&lt;/strong&gt; or &lt;a href="http://matplotlib.org/users/colormaps.html"&gt;&lt;strong&gt;matplotlib colormap&lt;/strong&gt;&lt;/a&gt;(except jet, which you should never use). It can also take a &lt;strong&gt;list of colors&lt;/strong&gt; specified in any valid matplotlib format (RGB tuples, &lt;strong&gt;hex color codes&lt;/strong&gt;, or HTML color names). 
The return value is always a list of RGB tuples. This allows you to use your own color palettes in graph.
&lt;/div&gt;

&lt;h2&gt;Barplots&lt;/h2&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;sns.set(style="ticks")

flatui = ["#9b59b6", "#3498db", "#95a5a6", "#e74c3c", "#34495e", "#2ecc71"]

# This Function takes as input a custom palette 
g = sns.barplot(x="sex", y="tip", hue="day", 
    palette=sns.color_palette(flatui),data=tips,ci=None)

# remove the top and right line in graph
sns.despine()

# Set the size of the graph from here
g.figure.set_size_inches(12,7)
# Set the Title of the graph from here
g.axes.set_title('Do We tend to \nTip high on Weekends?', 
    fontsize=34,color="b",alpha=0.3)
# Set the xlabel of the graph from here
g.set_xlabel("Gender",size = 67,color="g",alpha=0.5)
# Set the ylabel of the graph from here
g.set_ylabel("Mean Tips",size = 67,color="r",alpha=0.5)
# Set the ticklabel size and color of the graph from here
g.tick_params(labelsize=14,labelcolor="black")
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/barplot.png"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2&gt;Histograms and Distribution Diagrams&lt;/h2&gt;
&lt;p&gt;They form another part of my workflow. Lets plot the normal Histogram using seaborn. 
For this we will use the &lt;a href="http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.distplot.html#seaborn.distplot"&gt;&lt;strong&gt;distplot&lt;/strong&gt;&lt;/a&gt; function. This function combines the matplotlib hist function (with automatic calculation of a good default bin size) with the seaborn kdeplot() function. 
It can also fit &lt;strong&gt;scipy.stats&lt;/strong&gt; distributions and plot the estimated PDF over the data.&lt;/p&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# Create a list of 1000 Normal RVs
x = np.random.normal(size=1000)

sns.set_context("poster")
sns.set_style("ticks")
# This  Function creates a normed Histogram by default. 
# If we use the parameter kde=False and norm_hist=False then 
# we will be using a count histogram

g=sns.distplot(x,
            kde_kws={"color":"g","lw":4,"label":"KDE Estim","alpha":0.5},
            hist_kws={"color":"r","alpha":0.3,"label":"Freq"})


# remove the top and right line in graph
sns.despine()

# Set the size of the graph from here
g.figure.set_size_inches(12,7)
# Set the Title of the graph from here
g.axes.set_title('Normal Simulation', fontsize=34,color="b",alpha=0.3)
# Set the xlabel of the graph from here
g.set_xlabel("X",size = 67,color="g",alpha=0.5)
# Set the ylabel of the graph from here
g.set_ylabel("Density",size = 67,color="r",alpha=0.5)
# Set the ticklabel size and color of the graph from here
g.tick_params(labelsize=14,labelcolor="black")
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/hist_normal.png"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;import scipy.stats as stats

a = 1.5
b = 1.5
x = np.arange(0.01, 1, 0.01)
y = stats.beta.rvs(a,b,size=10000)
y_act = stats.beta.pdf(x,a,b)
g=sns.distplot(y,kde=False,norm_hist=True,
            kde_kws={"color":"g","lw":4,"label":"KDE Estim","alpha":0.5},
            hist_kws={"color":"r","alpha":0.3,"label":"Freq"})
# Note that we plotted on the graph using plt matlabplot function
plt.plot(x,y_act)

# remove the top and right line in graph
sns.despine()

# Set the size of the graph from here
g.figure.set_size_inches(12,7)
# Set the Title of the graph from here
g.axes.set_title(("Beta Simulation vs. Calculated Beta Density\nFor a=%s,b=%s")
    %(a,b),fontsize=34,color="b",alpha=0.3)
# Set the xlabel of the graph from here
g.set_xlabel("X",size = 67,color="g",alpha=0.5)
# Set the ylabel of the graph from here
g.set_ylabel("Density",size = 67,color="r",alpha=0.5)
# Set the ticklabel size and color of the graph from here
g.tick_params(labelsize=14,labelcolor="black")
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/hist_beta.png"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;h2&gt;PairPlots&lt;/h2&gt;
&lt;p&gt;You need to see how variables vary with one another. What is the distribution of variables in the dataset. This is the graph to use with the &lt;a href="http://stanford.edu/~mwaskom/software/seaborn/generated/seaborn.pairplot.html#seaborn.pairplot"&gt;&lt;strong&gt;pairplot&lt;/strong&gt;&lt;/a&gt; function. Very helpful And Seaborn males it a joy to use. We will use &lt;strong&gt;Iris Dataset&lt;/strong&gt; here for this example.&lt;/p&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;iris = sns.load_dataset("iris")
iris.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/iris.png" height="500" width="600"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;pre style="font-size:80%; padding:7px; margin:0em;"&gt;
&lt;code class="python"&gt;# Create a Pairplot
g = sns.pairplot(iris,hue="species",palette="muted",size=5, 
    vars=["sepal_width", "sepal_length"],kind='reg',markers=['o','x','+'])

# To change the size of the scatterpoints in graph
g = g.map_offdiag(plt.scatter,  s=35,alpha=0.5)

# remove the top and right line in graph
sns.despine()
# Additional line to adjust some appearance issue
plt.subplots_adjust(top=0.9)

# Set the Title of the graph from here
g.fig.suptitle('Relation between Sepal Width and Sepal Length', 
    fontsize=34,color="b",alpha=0.3)
&lt;/code&gt;&lt;/pre&gt;

&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;&lt;img src="/images/pairplot.png"&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;Hope you found this post useful and worth your time. You can find the iPython notebook at &lt;a href="https://github.com/MLWhiz/visualization/blob/master/Graphs.ipynb"&gt;github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I tried to make this as simple as possible but You may always &lt;strong&gt;ask me&lt;/strong&gt; or see the documentation for doubts.&lt;/p&gt;
&lt;p&gt;If you have &lt;strong&gt;any more ideas&lt;/strong&gt; on how to use Seaborn or &lt;strong&gt;which graphs should i add here&lt;/strong&gt;, please suggest in the &lt;strong&gt;comments&lt;/strong&gt; section.&lt;/p&gt;
&lt;p&gt;I will definitely try to add to this post as I start using more visualizations and encounter other libraries as good as seaborn.&lt;/p&gt;
&lt;p&gt;Till then ciao!!&lt;/p&gt;</summary><category term="Python Visualizations"></category><category term="Seaborn"></category><category term="Matplotlib"></category><category term="ggplot2"></category><category term="stanford software seaborn"></category><category term="regplot"></category><category term="lmplot seaborn"></category><category term="pairplot seaborn"></category><category term=""></category></entry><entry><title>Beautiful Sadness</title><link href="http://manishbarnwal.github.io/blog/2014/06/03/beautiful_sadness/" rel="alternate"></link><updated>2014-06-03T10:00:00-03:00</updated><author><name>Manish Barnwal</name></author><id>tag:manishbarnwal.github.io,2014-06-03:blog/2014/06/03/beautiful_sadness/</id><summary type="html">&lt;p&gt;As I woke up this morning, it took me a few moments to realize where I was. I looked around, gained my consciousness and a thought thundered into my mind –I was not in Kgp. Not anymore. Life at Kgp is now a past, a past which will always be cherished and remembered as the guide of all my future endeavors. I had heard that time flies but this fast I didn’t had even an iota of idea. The five years passed by in a blink.&lt;/p&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;p&gt;When  you leave Kgp, you find yourself juggling with thoughts. You experience mixed emotions of both happiness and sadness or rather a term –‘beautiful sadness’ perfectly contain these feelings. You feel sad for the life of peace is over –the phenomenal five years. At the same time you find yourself smiling that Kgp happened to you, that you had your best time here, that you couldn’t have imagined a better college life.&lt;/p&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;p&gt;Thank you Kgp for making me what I’m today and know that you’ll play a prominent role in whatever I aspire to become in my future. You are one of the best things that has happened to me in my past five years. Kgp, you have introduced me to some of the most amazing people, well some weird ones as well and a fewer limited editions.&lt;/p&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;p&gt;Now that we’re separated, I feel the void that has been created between us. But know that no one can ever fill this space of yours. You will always be special and I want you to know that just a thought of yours will automatically bring a smile on my lips. Thank you for the wonderful time we had together. Kgp, thou shall always be missed.&lt;/p&gt;
&lt;p&gt;Yours forever,&lt;/p&gt;
&lt;p&gt;--Just another Kgpian &lt;/p&gt;
&lt;p&gt;&lt;img alt="photo of kgp" src="http://manishbarnwal.com/images/beatiful_sadness.jpg" /&gt;&lt;/p&gt;</summary><category term="college"></category><category term="life"></category><category term="thoughts"></category><category term="nostalgia"></category></entry></feed>