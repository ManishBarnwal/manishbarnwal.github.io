<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>mlwhiz</title><link href="http://mlwhiz.github.io/" rel="alternate"></link><link href="http://mlwhiz.github.io/feeds/statistics.atom.xml" rel="self"></link><id>http://mlwhiz.github.io/</id><updated>2015-08-21T04:43:00-03:00</updated><entry><title>Behold the power of MCMC</title><link href="http://mlwhiz.github.io/blog/2015/08/21/MCMC_Algorithms_Cryptography/" rel="alternate"></link><updated>2015-08-21T04:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2015-08-21:blog/2015/08/21/MCMC_Algorithms_Cryptography/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/mcmc.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;Last time I wrote an article on MCMC and how they could be useful. We learned how MCMC chains could be used to simulate from a random variable whose distribution is partially known i.e. we don't know the normalizing constant.&lt;/p&gt;
&lt;p&gt;So MCMC Methods may sound interesting to some (for these what follows is a treat) and for those who don't really appreciate MCMC till now, I hope I will be able to pique your interest by the end of this blog post.&lt;/p&gt;
&lt;p&gt;So here goes. This time we will cover some applications of MCMC in various areas of Computer Science using Python. If you feel the problems difficult to follow with, I would advice you to go back and read the &lt;a href="http://mlwhiz.com/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/"&gt;previous post&lt;/a&gt;, which tries to explain MCMC Methods. We Will try to solve the following two problems:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Breaking the Code&lt;/strong&gt; - This problem has got somewhat of a great pedigree as this method was suggested by Persi Diaconis- The Mathemagician. So Someone comes to you with the below text. This text looks like gibberish but this is a code, Could you decrypyt it?&lt;br&gt;&lt;br&gt; &lt;em&gt;XZ STAVRK HXVR MYAZ OAKZM JKSSO SO MYR OKRR XDP JKSJRK XBMASD SO YAZ TWDHZ MYR JXMBYNSKF BSVRKTRM NYABY NXZ BXKRTRZZTQ OTWDH SVRK MYR AKSD ERPZMRXP KWZMTRP MYR JXTR OXBR SO X QSWDH NSIXD NXZ KXAZRP ORRETQ OKSI MYR JATTSN XDP X OXADM VSABR AIJRKORBMTQ XKMABWTXMRP MYR NSKPZ TRM IR ZRR MYR BYATP XDP PAR MYR ZWKHRSD YXP ERRD ZAMMADH NAMY YAZ OXBR MWKDRP MSNXKPZ MYR OAKR HAVADH MYR JXTIZ SO YAZ YXDPZ X NXKI XDP X KWE XTMRKDXMRTQ XZ MYR QSWDH NSIXD ZJSFR YR KSZR XDP XPVXDBADH MS MYR ERP Z YRXP ZXAP NAMY ISKR FADPDRZZ MYXD IAHYM YXVR ERRD RGJRBMRP SO YAI&lt;/em&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;The Knapsack Problem&lt;/strong&gt; - This problem comes from &lt;a href="http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I"&gt;Introduction to probability&lt;/a&gt; by Joseph Blitzstein. You should check out his courses (&lt;a href="http://projects.iq.harvard.edu/stat110/handouts"&gt;STAT110&lt;/a&gt; And &lt;a href="http://cm.dce.harvard.edu/2014/01/14328/publicationListing.shtml"&gt;CS109&lt;/a&gt;) as they are awesome. Also as it turns out Diaconis was the advisor of Joseph. So you have Bilbo a Thief who goes to Smaug's Lair. He finds M treasures. Each treasure has some Weight and some Gold value. But Bilbo cannot really take all of that. He could only carry a certain Maximum Weight. But being a smart hobbit, he wants to Maximize the value of the treasures he takes. Given the values for weights and value of the treasures and the maximum weight that Bilbo could carry, could you find a good solution? This is known as the Knapsack Problem in Computer Science.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="breaking-the-code"&gt;Breaking the Code&lt;/h2&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/security.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;So we look at the data and form a hypothesis that the data has been scrambled using a Substitution Cipher. We don't know the encryption key, and we would like to know the Decryption Key so that we can decrypt the data and read the code.&lt;/p&gt;
&lt;p&gt;To create this example, this data has actually been taken from Oliver Twist. We scrambled the data using a random encryption key, which we forgot after encrypting and we would like to decrypt this encrypted text using MCMC Chains. The real decryption key actually is &amp;quot;ICZNBKXGMPRQTWFDYEOLJVUAHS&amp;quot;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So lets think about this problem for a little bit. The decryption key could be any 26 letter string with all alphabets appearing exactly once. How many string permutations are there like that? That number would come out to be &lt;span class="math inline"&gt;\(26! \approx 10^{26}\)&lt;/span&gt; permutations. That is a pretty large number. If we go for using a brute force approach we are screwed. So what could we do? MCMC Chains come to rescue.&lt;/p&gt;
&lt;p&gt;We will devise a Chain whose states theoritically could be any of these permutations. Then we will:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Start by picking up a random current state.&lt;/li&gt;
&lt;li&gt;Create a proposal for a new state by swapping two random letters in the current state.&lt;/li&gt;
&lt;li&gt;Use a Scoring Function which calculates the score of the current state &lt;span class="math inline"&gt;\(Score_C\)&lt;/span&gt; and the proposed State &lt;span class="math inline"&gt;\(Score_P\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;If the score of the proposed state is more than current state, Move to Proposed State.&lt;/li&gt;
&lt;li&gt;Else flip a coin which has a probability of Heads &lt;span class="math inline"&gt;\(Score_P/Score_C\)&lt;/span&gt;. If it comes heads move to proposed State.&lt;/li&gt;
&lt;li&gt;Repeat from 2nd State.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If we get lucky we may reach a steady state where the chain has the stationary distribution of the needed states and the state that the chain is at could be used as a solution.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So the Question is what is the scoring function that we will want to use. We want to use a scoring function for each state(Decryption key) which assigns a positive score to each decryption key. This score intuitively should be more if the encrypted text looks more like actual english if decrypted using this decryption key.&lt;/p&gt;
&lt;p&gt;So how can we quantify such a function. We will check a long text and calculate some statistics. See how many times one alphabet comes after another in a legitimate long text like War and Peace. For example we want to find out how many times does 'BA' appears in the text or how many times 'TH' occurs in the text.&lt;/p&gt;
&lt;p&gt;For each pair of characters &lt;span class="math inline"&gt;\(\beta_1\)&lt;/span&gt; and &lt;span class="math inline"&gt;\(\beta_2\)&lt;/span&gt; (e.g. &lt;span class="math inline"&gt;\(\beta_1\)&lt;/span&gt; = T and &lt;span class="math inline"&gt;\(\beta_2\)&lt;/span&gt; =H), we let &lt;span class="math inline"&gt;\(R(\beta_1,\beta_2)\)&lt;/span&gt; record the number of times that specific pair(e.g. &amp;quot;TH&amp;quot;) appears consecutively in the reference text.&lt;/p&gt;
&lt;p&gt;Similarly, for a putative decryption key x, we let &lt;span class="math inline"&gt;\(F_x(\beta_1,\beta_2)\)&lt;/span&gt; record the number of times that pair appears when the cipher text is decrypted using the decryption key x.&lt;/p&gt;
&lt;p&gt;We then Score a particular decryption key x using:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[Score(x) = \prod R(\beta_1,\beta_2)^{F_x(\beta_1,\beta_2)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This function can be thought of as multiplying, for each consecutive pair of letters in the decrypted text, the number of times that pair occurred in the reference text. Intuitively, the score function is higher when the pair frequencies in the decrypted text most closely match those of the reference text, and the decryption key is thus most likely to be correct.&lt;/p&gt;
&lt;p&gt;To make life easier with calculations we will calculate &lt;span class="math inline"&gt;\(log(Score(x))\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So lets start working through the problem step by step.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;
# AIM: To Decrypt a text using MCMC approach. i.e. find decryption key which we will call cipher from now on.
import string
import math
import random

# This function takes as input a decryption key and creates a dict for key where each letter in the decryption key
# maps to a alphabet For example if the decryption key is "DGHJKL...." this function will create a dict like {D:A,G:B,H:C....} 
def create_cipher_dict(cipher):
    cipher_dict = {}
    alphabet_list = list(string.ascii_uppercase)
    for i in range(len(cipher)):
        cipher_dict[alphabet_list[i]] = cipher[i]
    return cipher_dict

# This function takes a text and applies the cipher/key on the text and returns text.
def apply_cipher_on_text(text,cipher):
    cipher_dict = create_cipher_dict(cipher) 
    text = list(text)
    newtext = ""
    for elem in text:
        if elem.upper() in cipher_dict:
            newtext+=cipher_dict[elem.upper()]
        else:
            newtext+=" "
    return newtext

# This function takes as input a path to a long text and creates scoring_params dict which contains the 
# number of time each pair of alphabet appears together
# Ex. {'AB':234,'TH':2343,'CD':23 ..}
def create_scoring_params_dict(longtext_path):
    scoring_params = {}
    alphabet_list = list(string.ascii_uppercase)
    with open(longtext_path) as fp:
        for line in fp:
            data = list(line.strip())
            for i in range(len(data)-1):
                alpha_i = data[i].upper()
                alpha_j = data[i+1].upper()
                if alpha_i not in alphabet_list and alpha_i != " ":
                    alpha_i = " "
                if alpha_j not in alphabet_list and alpha_j != " ":
                    alpha_j = " "
                key = alpha_i+alpha_j
                if key in scoring_params:
                    scoring_params[key]+=1
                else:
                    scoring_params[key]=1
    return scoring_params

# This function takes as input a text and creates scoring_params dict which contains the 
# number of time each pair of alphabet appears together
# Ex. {'AB':234,'TH':2343,'CD':23 ..}

def score_params_on_cipher(text):
    scoring_params = {}
    alphabet_list = list(string.ascii_uppercase)
    data = list(text.strip())
    for i in range(len(data)-1):
        alpha_i =data[i].upper()
        alpha_j = data[i+1].upper()
        if alpha_i not in alphabet_list and alpha_i != " ":
            alpha_i = " "
        if alpha_j not in alphabet_list and alpha_j != " ":
            alpha_j = " "
        key = alpha_i+alpha_j
        if key in scoring_params:
            scoring_params[key]+=1
        else:
            scoring_params[key]=1
    return scoring_params

# This function takes the text to be decrypted and a cipher to score the cipher.
# This function returns the log(score) metric

def get_cipher_score(text,cipher,scoring_params):
    cipher_dict = create_cipher_dict(cipher)
    decrypted_text = apply_cipher_on_text(text,cipher)
    scored_f = score_params_on_cipher(decrypted_text)
    cipher_score = 0
    for k,v in scored_f.iteritems():
        if k in scoring_params:
            cipher_score += v*math.log(scoring_params[k])
    return cipher_score

# Generate a proposal cipher by swapping letters at two random location
def generate_cipher(cipher):
    pos1 = random.randint(0, len(list(cipher))-1)
    pos2 = random.randint(0, len(list(cipher))-1)
    if pos1 == pos2:
        return generate_cipher(cipher)
    else:
        cipher = list(cipher)
        pos1_alpha = cipher[pos1]
        pos2_alpha = cipher[pos2]
        cipher[pos1] = pos2_alpha
        cipher[pos2] = pos1_alpha
        return "".join(cipher)

# Toss a random coin with robability of head p. If coin comes head return true else false.
def random_coin(p):
    unif = random.uniform(0,1)
    if unif&gt;=p:
        return False
    else:
        return True
    
# Takes as input a text to decrypt and runs a MCMC algorithm for n_iter. Returns the state having maximum score and also
# the last few states 
def MCMC_decrypt(n_iter,cipher_text,scoring_params):
    current_cipher = string.ascii_uppercase # Generate a random cipher to start
    state_keeper = set()
    best_state = ''
    score = 0
    for i in range(n_iter):
        state_keeper.add(current_cipher)
        proposed_cipher = generate_cipher(current_cipher)
        score_current_cipher = get_cipher_score(cipher_text,current_cipher,scoring_params)
        score_proposed_cipher = get_cipher_score(cipher_text,proposed_cipher,scoring_params)
        acceptance_probability = min(1,math.exp(score_proposed_cipher-score_current_cipher))
        if score_current_cipher&gt;score:
            best_state = current_cipher
        if random_coin(acceptance_probability):
            current_cipher = proposed_cipher
        if i%500==0:
            print "iter",i,":",apply_cipher_on_text(cipher_text,current_cipher)[0:99]
    return state_keeper,best_state

## Run the Main Program:

scoring_params = create_scoring_params_dict('war_and_peace.txt')

plain_text = "As Oliver gave this first proof of the free and proper action of his lungs, \
the patchwork coverlet which was carelessly flung over the iron bedstead, rustled; \
the pale face of a young woman was raised feebly from the pillow; and a faint voice imperfectly \
articulated the words, Let me see the child, and die. \
The surgeon had been sitting with his face turned towards the fire: giving the palms of his hands a warm \
and a rub alternately. As the young woman spoke, he rose, and advancing to the bed's head, said, with more kindness \
than might have been expected of him: "

encryption_key = "XEBPROHYAUFTIDSJLKZMWVNGQC"
cipher_text = apply_cipher_on_text(plain_text,encryption_key)
decryption_key = "ICZNBKXGMPRQTWFDYEOLJVUAHS"

print"Text To Decode:", cipher_text
print "\n"
states,best_state = MCMC_decrypt(10000,cipher_text,scoring_params)
print "\n"
print "Decoded Text:",apply_cipher_on_text(cipher_text,best_state)
print "\n"
print "MCMC KEY FOUND:",best_state
print "ACTUAL DECRYPTION KEY:",decryption_key
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/result1_MCMC.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This chain converges around the 2000th iteration and we are able to unscramble the code. That's awesome!!! Now as you see the MCMC Key found is not exactly the encryption key. So the solution is not a deterministic one, but we can see that it does not actually decrease any of the value that the MCMC Methods provide. Now Lets Help Bilbo :)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="the-knapsack-problem"&gt;The Knapsack Problem&lt;/h1&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Restating, we have Bilbo a Thief who goes to Smaug's Lair. He finds M treasures. Each treasure has some Weight and some Gold value. But Bilbo cannot really take all of that. He could only carry a certain Maximum Weight. But being a smart hobbit, he wants to Maximize the value of the treasures he takes. Given the values for weights and value of the treasures and the maximum weight that Bilbo could carry, could you find a good solution?&lt;/p&gt;
&lt;p&gt;So in this problem we have an &lt;span class="math inline"&gt;\(1\)&lt;/span&gt;x&lt;span class="math inline"&gt;\(M\)&lt;/span&gt; array of Weight Values W, Gold Values G and a value for the maximum weight &lt;span class="math inline"&gt;\(w_{MAX}\)&lt;/span&gt; that Bilbo can carry. We want to find out an &lt;span class="math inline"&gt;\(1\)&lt;/span&gt;x&lt;span class="math inline"&gt;\(M\)&lt;/span&gt; array &lt;span class="math inline"&gt;\(X\)&lt;/span&gt; of 1's and 0's, which holds weather Bilbo Carries a particular treasure or not. This array needs to follow the constraint &lt;span class="math inline"&gt;\(WX^T &amp;lt; w_{MAX}\)&lt;/span&gt; and we want to maximize &lt;span class="math inline"&gt;\(GX^T\)&lt;/span&gt; for a particular state X.(Here the T means transpose)&lt;/p&gt;
&lt;p&gt;So lets first discuss as to how we will create a proposal from a previous state.&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Pick a random index from the state and toggle the index value.&lt;/li&gt;
&lt;li&gt;Check if we satisfy our constraint. If yes this state is the proposal state.&lt;/li&gt;
&lt;li&gt;Else pick up another random index and repeat.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We also need to think about the Scoring Function. We need to give high values to states with high gold value. We will use: &lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[Score(X)=e^{\beta GX^T}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We give exponentially more value to higher score. The Beta here is a +ve constant. But how to choose it? If &lt;span class="math inline"&gt;\(\beta\)&lt;/span&gt; is big we will give very high score to good solutions and the chain will not be able to try new solutions as it can get stuck in local optimas. If we give a small value the chain will not converge to very good solutions. So weuse an Optimization Technique called &lt;strong&gt;&lt;a href="https://en.wikipedia.org/wiki/Simulated_annealing"&gt;Simulated Annealing&lt;/a&gt;&lt;/strong&gt; i.e. we will start with a small value of &lt;span class="math inline"&gt;\(\beta\)&lt;/span&gt; and increase as no of iterations go up. That way the chain will explore in the starting stages and stay at the best solution in the later stages.&lt;/p&gt;
&lt;p&gt;So now we have everything we need to get started&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;
import numpy as np

W = [20,40,60,12,34,45,67,33,23,12,34,56,23,56]
G = [120,420,610,112,341,435,657,363,273,812,534,356,223,516]
W_max = 150

# This function takes a state X , The gold vector G and a Beta Value and return the Log of score
def score_state_log(X,G,Beta):
    return Beta*np.dot(X,G)

# This function takes as input a state X and the number of treasures M, The weight vector W and the maximum weight W_max
# and returns a proposal state
def create_proposal(X,W,W_max):
    M = len(W)
    random_index = random.randint(0,M-1)
    #print random_index
    proposal = list(X)
    proposal[random_index] = 1 - proposal[random_index]  #Toggle
    #print proposal
    if np.dot(proposal,W)&lt;=W_max:
        return proposal
    else:
        return create_proposal(X,W,W_max)
    
# Takes as input a text to decrypt and runs a MCMC algorithm for n_iter. Returns the state having maximum score and also
# the last few states 
def MCMC_Golddigger(n_iter,W,G,W_max, Beta_start = 0.05, Beta_increments=.02):
    M = len(W)
    Beta = Beta_start
    current_X = [0]*M # We start with all 0's
    state_keeper = []
    best_state = ''
    score = 0
    
    for i in range(n_iter):
        state_keeper.append(current_X)
        proposed_X = create_proposal(current_X,W,W_max)

        score_current_X = score_state_log(current_X,G,Beta)
        score_proposed_X = score_state_log(proposed_X,G,Beta)
        acceptance_probability = min(1,math.exp(score_proposed_X-score_current_X))
        if score_current_X&gt;score:
            best_state = current_X
        if random_coin(acceptance_probability):
            current_X = proposed_X
        if i%500==0:
            Beta += Beta_increments 
        # You can use these below two lines to tune value of Beta
        #if i%20==0:
        #    print "iter:",i," |Beta=",Beta," |Gold Value=",np.dot(current_X,G)
            
    return state_keeper,best_state
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Running the Main program:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;
max_state_value =0 
Solution_MCMC = [0]
for i in range(10):
    state_keeper,best_state = MCMC_Golddigger(50000,W,G,W_max,0.0005, .0005)
    state_value=np.dot(best_state,G)
    if state_value&gt;max_state_value:
        max_state_value = state_value
        Solution_MCMC = best_state

print "MCMC Solution is :" , str(Solution_MCMC) , "with Gold Value:", str(max_state_value)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;pre&gt;&lt;code&gt;MCMC Solution is : [0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0] with Gold Value: 2435&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now I won't say that this is the best solution. The deterministic solution using DP will be the best for such use case but sometimes when the problems gets large, having such techniques at disposal becomes invaluable.&lt;/p&gt;
&lt;p&gt;So tell me What do you think about MCMC Methods?&lt;/p&gt;
&lt;p&gt;Also, If you find any good applications or would like to apply these techniques to some area, I would really be glad to know about them and help if possible.&lt;/p&gt;
&lt;p&gt;The codes for both examples are sourced at &lt;a href="https://github.com/MLWhiz/MCMC_Project"&gt;Github&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="references-and-sources"&gt;References and Sources:&lt;/h2&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I"&gt;Introduction to Probability Joseph K Blitzstein, Jessica Hwang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://statweb.stanford.edu/~cgates/PERSI/papers/MCMCRev.pdf"&gt;The Markov Chain Monte Carlo Revolution, Persi Diaconis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.utstat.toronto.edu/wordpress/WSFiles/technicalreports/1005.pdf"&gt;Decrypting Classical Cipher Text Using Markov Chain Monte Carlo, Jian Chen and Jeffrey S. Rosenthal&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;/p&gt;</summary><category term="Statistics"></category><category term="python"></category></entry><entry><title>My Tryst With MCMC Algorithms</title><link href="http://mlwhiz.github.io/blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/" rel="alternate"></link><updated>2015-08-19T13:43:00-03:00</updated><author><name>Rahul Agarwal</name></author><id>tag:mlwhiz.github.io,2015-08-19:blog/2015/08/19/MCMC_Algorithms_Beta_Distribution/</id><summary type="html">&lt;p&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
The things that I find hard to understand push me to my limits. One of the things that I have always found hard is &lt;strong&gt;Markov Chain Monte Carlo Methods&lt;/strong&gt;. When I first encountered them, I read a lot about them but mostly it ended like this.
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/flabbergasted.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;The meaning is normally hidden in deep layers of Mathematical noise and not easy to decipher. This blog post is intended to clear up the confusion around MCMC methods, Know what they are actually useful for and Get hands on with some applications.&lt;/p&gt;
&lt;h2 id="so-what-really-are-mcmc-methods"&gt;&lt;strong&gt;So what really are MCMC Methods?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;First of all we have to understand what are &lt;strong&gt;&lt;em&gt;Monte Carlo&lt;/em&gt;&lt;/strong&gt; Methods!!!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Monte_Carlo_method"&gt;Monte Carlo&lt;/a&gt; methods derive their name from Monte Carlo Casino in Monaco. There are many card games that need probability of winning against the dealer. Sometimes calculating this probability can be mathematically complex or highly intractable. But we can always run a computer simulation to simulate the whole game many times and see the probability as the number of wins divided by the number of games played.&lt;/p&gt;
&lt;p&gt;So that is all you need to know about Monte carlo Methods. Yes it is just a simple simulation technique with a Fancy Name.&lt;/p&gt;
&lt;p&gt;So as we have got the first part of MCMC, we also need to understand what are &lt;strong&gt;&lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Markov_chain"&gt;Markov Chains&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;. Before Jumping onto Markov Chains let us learn a little bit about &lt;strong&gt;Markov Property&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Suppose you have a system of &lt;span class="math inline"&gt;\(M\)&lt;/span&gt; possible states, and you are hopping from one state to another. &lt;em&gt;Markov Property&lt;/em&gt; says that given a process which is at a state &lt;span class="math inline"&gt;\(X_n\)&lt;/span&gt; at a particular point of time, the probability of &lt;span class="math inline"&gt;\(X_{n+1} = k\)&lt;/span&gt;, where &lt;span class="math inline"&gt;\(k\)&lt;/span&gt; is any of the &lt;span class="math inline"&gt;\(M\)&lt;/span&gt; states the process can hop to, will only be dependent on which state it is at the given moment of time. And not on how it reached the current state.&lt;/p&gt;
&lt;p&gt;Mathematically speaking:&lt;/p&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[ P(X_{n+1}=k | X_n=k_n,X_{n-1}=k_{n-1},....,X_1=k_1) = P(X_{n+1}=k|X_n=k_n)\]&lt;/span&gt;
&lt;/center&gt;
&lt;p&gt;If a process exhibits the Markov Property than it is known as a Markov Process.&lt;/p&gt;
&lt;p&gt;Now Why is a Markov Chain important? It is important because of its &lt;strong&gt;stationary distribution&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So what is a &lt;strong&gt;Stationary Distribution&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;Assume you have a markov process like below. You start from any state &lt;span class="math inline"&gt;\(X_i\)&lt;/span&gt; and want to find out the state Probability distribution at &lt;span class="math inline"&gt;\(X_{i+1}\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: 10px; margin-bottom: -10px;"&gt;
&lt;center&gt;
&lt;img src="/images/Finance_Markov_chain_example_state_space.svg"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
You have a matrix of transition probability
&lt;div style="margin-top: 9px; margin-bottom: 10px;"&gt;
&lt;center&gt;
&lt;img src="/images/transition_matrix.png"&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;which defines the probability of going from a state &lt;span class="math inline"&gt;\(X_i\)&lt;/span&gt; to &lt;span class="math inline"&gt;\(X_j\)&lt;/span&gt;. You start calculating the Probability distribution for the next state. If you are at Bull Market State at time &lt;span class="math inline"&gt;\(i\)&lt;/span&gt; , you have a state Probability distribution as [0,1,0]&lt;/p&gt;
&lt;p&gt;you want to get the state pdf at &lt;span class="math inline"&gt;\(X_{i+1}\)&lt;/span&gt;. That is given by&lt;/p&gt;
&lt;div&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[s_{i+1} = s_{i}Q\]&lt;/span&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[ s_{i+1}=\left[ {\begin{array}{cc}   .15 &amp;amp; .8 &amp;amp; .05      \end{array} } \right]\]&lt;/span&gt;
&lt;/center&gt;
&lt;/div&gt;
&lt;p&gt;And the next state distribution could be found out by&lt;/p&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[s_{i+1} = s_iQ^2\]&lt;/span&gt;
&lt;/center&gt;
and so on. Eventually you will reach a stationary state s where:
&lt;center&gt;
&lt;span class="math display"&gt;\[sQ=s\]&lt;/span&gt;
&lt;/center&gt;
For this transition matrix Q the Stationary distribution &lt;span class="math inline"&gt;\(s\)&lt;/span&gt; is
&lt;center&gt;
&lt;span class="math display"&gt;\[ s_{i+1}=\left[ {\begin{array}{cc}   .625 &amp;amp; .3125 &amp;amp; .0625      \end{array} } \right]\]&lt;/span&gt;
&lt;/center&gt;
&lt;p&gt;The stationary state distribution is important because it lets you define the probability for every state of a system at a random time. That is for this particular example we can say that 62.5% of the times market will be in a bull market state, 31.25% of weeks it will be a bear market and 6.25% of weeks it will be stagnant&lt;/p&gt;
&lt;p&gt;Intuitively you can think of it as an random walk on a chain. You might visit some nodes more often than others based on node probabilities. In the &lt;em&gt;Google Pagerank&lt;/em&gt; problem you might think of a node as a page, and the probability of a page in the stationary distribution as its relative importance.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Woah!&lt;/em&gt;&lt;/strong&gt; That was a lot of information and we have yet not started talking about the MCMC Methods. Well if you are with me till now, we can now get on to the real topic now.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="so-what-is-mcmc"&gt;So What is MCMC?&lt;/h2&gt;
According to &lt;a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo"&gt;Wikipedia&lt;/a&gt;:
&lt;blockquote&gt;
&lt;strong&gt;Markov Chain Monte Carlo&lt;/strong&gt; (MCMC) methods are a class of algorithms for &lt;strong&gt;sampling from a probability distribution&lt;/strong&gt; based on constructing a Markov chain that has the desired distribution as its stationary distribution. The state of the chain after a number of steps is then used as a sample of the desired distribution. The quality of the sample improves as a function of the number of steps.
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;So let's explain this with an example: Assume that &lt;strong&gt;we want to sample from a &lt;a href="https://en.wikipedia.org/wiki/Beta_distribution"&gt;Beta distribution&lt;/a&gt;&lt;/strong&gt;. The &lt;em&gt;PDF&lt;/em&gt; is:&lt;/p&gt;
&lt;center&gt;
&lt;span class="math display"&gt;\[f(x) = Cx^{\alpha -1}(1-x)^{\beta -1}\]&lt;/span&gt;
&lt;/center&gt;
&lt;p&gt;where &lt;span class="math inline"&gt;\(C\)&lt;/span&gt; is the normalizing constant &lt;em&gt;(which we actually don't need to Sample from the distribution as we will see later)&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This is a &lt;strong&gt;fairly difficult problem&lt;/strong&gt; with the Beta Distribution if not intractable. In reality you might need to work with a lot harder Distribution Functions and sometimes you won't actually know the normalizing constants.&lt;/p&gt;
&lt;p&gt;MCMC methods make life easier for us by providing us with algorithms that could create a Markov Chain which has the Beta distribution as its &lt;strong&gt;stationary distribution&lt;/strong&gt; given that we can sample from a uniform distribution(which is &lt;em&gt;fairly&lt;/em&gt; easy).&lt;/p&gt;
&lt;p&gt;If we start from a random state and traverse to the next state based on some algorithm repeatedly, we will end up creating a Markov Chain which has the Beta distribution as its &lt;strong&gt;stationary distribution&lt;/strong&gt; and the states we are at after a long time could be used as sample from the Beta Distribution.&lt;/p&gt;
&lt;p&gt;One such MCMC Algorithm is the &lt;strong&gt;&lt;a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm"&gt;Metropolis Hastings Algorithm&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id="metropolis-hastings-algorithm"&gt;Metropolis Hastings Algorithm&lt;/h2&gt;
&lt;p&gt;Let &lt;span class="math inline"&gt;\(s=(s_1,s_2,....,s_M)\)&lt;/span&gt; be the desired stationary distribution. We want to create a Markov Chain that has this stationary distribution. We start with an arbitrary Markov Chain &lt;span class="math inline"&gt;\(P\)&lt;/span&gt; with &lt;span class="math inline"&gt;\(M\)&lt;/span&gt; states with transition matrix &lt;span class="math inline"&gt;\(Q\)&lt;/span&gt;, so that &lt;span class="math inline"&gt;\(Q_{ij}\)&lt;/span&gt; represents the probability of going from state &lt;span class="math inline"&gt;\(i\)&lt;/span&gt; to &lt;span class="math inline"&gt;\(j\)&lt;/span&gt;. Intuitively we know how to wander around this Markov Chain but this Markov Chain does not have the required Stationary Distribution. This chain does have some stationary distribution(which is not of our use)&lt;/p&gt;
&lt;p&gt;Our Goal is to change the way we wander on the this Markov Chain &lt;span class="math inline"&gt;\(P\)&lt;/span&gt; so that this chain has the desired Stationary distribution.&lt;/p&gt;
&lt;p&gt;To do this we:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Start at a random initial State &lt;span class="math inline"&gt;\(i\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Randomly pick a new &lt;em&gt;Proposal State&lt;/em&gt; by looking at the transition probabilities in the ith row of the transition matrix Q.&lt;/li&gt;
&lt;li&gt;Compute an measure called the &lt;em&gt;Acceptance Probability&lt;/em&gt; which is defined as:
&lt;center&gt;
&lt;span class="math display"&gt;\[a_{ij} = min(s_jp_{ji}/s_{i}p_{ij},1)\]&lt;/span&gt;
&lt;/center&gt;&lt;/li&gt;
&lt;li&gt;Now Flip a coin that lands head with probability &lt;span class="math inline"&gt;\(a_{ij}\)&lt;/span&gt;. If the coin comes up heads, accept the proposal i.e move to next state else reject the proposal i.e. stay at the current state.&lt;/li&gt;
&lt;li&gt;Repeat for a long time&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After a long time this chain will converge and will have a stationary distribution &lt;span class="math inline"&gt;\(s\)&lt;/span&gt;. &lt;strong&gt;We can then use the states of the chain as the sample from any distribution.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While doing this to sample the Beta Distribution, the only time we are using the PDF is to find the acceptance probability and in that we divide &lt;span class="math inline"&gt;\(s_j\)&lt;/span&gt; by &lt;span class="math inline"&gt;\(s_i\)&lt;/span&gt;, i.e. the &lt;strong&gt;normalizing constant &lt;span class="math inline"&gt;\(C\)&lt;/span&gt; gets cancelled&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
Now Let's Talk about the intuition. For the Intuition I am quoting an &lt;a href="http://stats.stackexchange.com/a/12657"&gt;Answer&lt;/a&gt; from the site Stack Exchange,as this was the best intuitive explanation that I could find:
&lt;blockquote&gt;
I think there's a nice and simple intuition to be gained from the (independence-chain) Metropolis-Hastings algorithm. &lt;br&gt; &lt;br&gt; First, what's the goal? The goal of MCMC is to &lt;strong&gt;draw samples from some probability distribution&lt;/strong&gt; without having to know its exact height at any point(We don't need to know C). The way MCMC achieves this is to &lt;strong&gt;&amp;quot;wander around&amp;quot; on that distribution in such a way that the amount of time spent in each location is proportional to the height of the distribution&lt;/strong&gt;. If the &amp;quot;wandering around&amp;quot; process is set up correctly, you can make sure that this proportionality (between time spent and height of the distribution) is achieved. &lt;br&gt; &lt;br&gt; Intuitively, what we want to do is to to walk around on some (lumpy) surface in such a way that the amount of time we spend (or # samples drawn) in each location is proportional to the height of the surface at that location. So, e.g., we'd like to spend twice as much time on a hilltop that's at an altitude of 100m as we do on a nearby hill that's at an altitude of 50m. The nice thing is that we can do this even if we don't know the absolute heights of points on the surface: all we have to know are the relative heights. e.g., if one hilltop A is twice as high as hilltop B, then we'd like to spend twice as much time at A as we spend at B. &lt;br&gt; &lt;br&gt; The simplest variant of the Metropolis-Hastings algorithm (independence chain sampling) achieves this as follows: assume that in every (discrete) time-step, we pick a random new &amp;quot;proposed&amp;quot; location (selected uniformly across the entire surface). If the proposed location is higher than where we're standing now, move to it. If the proposed location is lower, then move to the new location with probability p, where p is the ratio of the height of that point to the height of the current location. (i.e., flip a coin with a probability p of getting heads; if it comes up heads, move to the new location; if it comes up tails, stay where we are). Keep a list of the locations you've been at on every time step, and that list will (asyptotically) have the right proportion of time spent in each part of the surface. (And for the A and B hills described above, you'll end up with twice the probability of moving from B to A as you have of moving from A to B). &lt;br&gt; &lt;br&gt; There are more complicated schemes for proposing new locations and the rules for accepting them, but the basic idea is still: &lt;strong&gt;(1) pick a new &amp;quot;proposed&amp;quot; location; (2) figure out how much higher or lower that location is compared to your current location; (3) probabilistically stay put or move to that location in a way that respects the overall goal of spending time proportional to height of the location. &amp;quot;&amp;quot;&amp;quot;&lt;/strong&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="sampling-from-beta-distribution"&gt;Sampling from Beta Distribution&lt;/h2&gt;
&lt;p&gt;Now Let's Move on to the problem of Simulating from Beta Distribution. Now Beta Distribution is a continuous Distribution on [0,1] and it can have infinite states on [0,1].&lt;/p&gt;
&lt;p&gt;Lets Assume an arbitrary Markov Chain P with infinite states on [0,1] having transition Matrix Q such that &lt;span class="math inline"&gt;\(Q_{ij} = Q_{ji} =\)&lt;/span&gt; All entries in Matrix. We don't really need the Matrix Q as we will see later, But I want to keep the problem description as close to the algorihm we suggested.&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Start at a random &lt;strong&gt;initial State &lt;span class="math inline"&gt;\(i\)&lt;/span&gt;&lt;/strong&gt; given by Unif(0,1).&lt;/li&gt;
&lt;li&gt;Randomly pick a new &lt;strong&gt;Proposal State&lt;/strong&gt; by looking at the transition probabilities in the ith row of the transition matrix Q. Lets say we pick up another Unif(0,1) state as a proposal state &lt;span class="math inline"&gt;\(j\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Compute an measure called the &lt;strong&gt;Acceptance Probability&lt;/strong&gt; :
&lt;center&gt;
&lt;span class="math display"&gt;\[a_{ij} = min(s_jp_{ji}/s_{i}p_{ij},1)\]&lt;/span&gt;
&lt;/center&gt;
which is,
&lt;center&gt;
&lt;span class="math display"&gt;\[a_{ij} = min(s_j/s_i,1)\]&lt;/span&gt;
&lt;/center&gt;
where,
&lt;center&gt;
&lt;span class="math display"&gt;\[s_i = Ci^{\alpha -1}(1-i)^{\beta -1}\]&lt;/span&gt;
&lt;/center&gt;
and,
&lt;center&gt;
&lt;span class="math display"&gt;\[s_j = Cj^{\alpha -1}(1-j)^{\beta -1}\]&lt;/span&gt;
&lt;/center&gt;&lt;/li&gt;
&lt;li&gt;Now Flip a coin that lands head with probability &lt;span class="math inline"&gt;\(a_{ij}\)&lt;/span&gt;. If the coin comes up heads, accept the proposal i.e move to next state else reject the proposal i.e. stay at the current state.&lt;/li&gt;
&lt;li&gt;Repeat for a long time&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So enough with theory, Let's Move on to python to create our Beta Simulations Now....&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;import random
# Lets define our Beta Function to generate s for any particular state. We don't care for the normalizing constant here.
def beta_s(w,a,b):
    return w**(a-1)*(1-w)**(b-1)

# This Function returns True if the coin with probability P of heads comes heads when flipped.
def random_coin(p):
    unif = random.uniform(0,1)
    if unif&gt;=p:
        return False
    else:
        return True

# This Function runs the MCMC chain for Beta Distribution.
def beta_mcmc(N_hops,a,b):
    states = []
    cur = random.uniform(0,1)
    for i in range(0,N_hops):
        states.append(cur)
        next = random.uniform(0,1)
        ap = min(beta_s(next,a,b)/beta_s(cur,a,b),1) # Calculate the acceptance probability
        if random_coin(ap):
            cur = next
    return states[-1000:] # Returns the last 100 states of the chain
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Let us check our results of the MCMC Sampled Beta distribution against the actual beta distribution.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;link rel="stylesheet" href="/theme/highlight/styles/default.css"&gt;
&lt;script src="/theme/highlight/highlight.pack.js"&gt;&lt;/script&gt;
&lt;script&gt;hljs.initHighlightingOnLoad();&lt;/script&gt;
&lt;pre style="font-size:80%; padding:7px; margin:0em; background-color:#000000;"&gt;
&lt;code class="python" style="background-color:#000000; color:#FFFFFF"&gt;
import numpy as np
import pylab as pl
import scipy.special as ss
%matplotlib inline
pl.rcParams['figure.figsize'] = (17.0, 4.0)

# Actual Beta PDF.
def beta(a, b, i):
    e1 = ss.gamma(a + b)
    e2 = ss.gamma(a)
    e3 = ss.gamma(b)
    e4 = i ** (a - 1)
    e5 = (1 - i) ** (b - 1)
    return (e1/(e2*e3)) * e4 * e5

# Create a function to plot Actual Beta PDF with the Beta Sampled from MCMC Chain.
def plot_beta(a, b):
    Ly = []
    Lx = []
    i_list = np.mgrid[0:1:100j]
    for i in i_list:
        Lx.append(i)
        Ly.append(beta(a, b, i))
    pl.plot(Lx, Ly, label="Real Distribution: a="+str(a)+", b="+str(b))
    pl.hist(beta_mcmc(100000,a,b),normed=True,bins =25, histtype='step',label="Simulated_MCMC: a="+str(a)+", b="+str(b))
    pl.legend()
    pl.show()
    
plot_beta(0.1, 0.1)
plot_beta(1, 1)
plot_beta(2, 3)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;div style="margin-top: -9px; margin-bottom: 30px;"&gt;
&lt;p&gt;&lt;img src="/images/graphs.png"&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;As we can see our sampled beta values closely resemble the beta distribution.&lt;/p&gt;
&lt;p&gt;So MCMC Methods are useful for the following basic problems.&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Simulating from a Random Variable PDF. Example: Simulate from a Beta(0.5,0.5) or from a Normal(0,1).&lt;/li&gt;
&lt;li&gt;Solve problems with a large state space.For Example: Knapsack Problem, Encrytion Cipher etc. We will work on this in the &lt;a href="http://mlwhiz.com/blog/2015/08/21/MCMC_Algorithms_Cryptography/"&gt;Next Blog Post&lt;/a&gt; as this one has already gotten bigger than what I expected.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Till Then Ciao!!!!!!&lt;/p&gt;
&lt;h2 id="references-and-sources"&gt;References and Sources:&lt;/h2&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;a href="http://www.amazon.com/Introduction-Probability-Chapman-Statistical-Science-ebook/dp/B00MMOJ19I"&gt;Introduction to Probability Joseph K Blitzstein, Jessica Hwang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/"&gt;Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://stats.stackexchange.com/a/12657"&gt;StackExchange&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;/p&gt;</summary><category term="Statistics"></category><category term="python"></category></entry></feed>